{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sqlContext=SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "employee_df=sqlContext.read.json(\"hdfs://nameservice1/user/edureka_294428/Employees.json\") #in webconsole, you can also use sqlContext instead of spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+\n",
      "| ID|     Name|Salary|\n",
      "+---+---------+------+\n",
      "|  1|     John| 20000|\n",
      "|  2|    Rohit| 15000|\n",
      "|  3|    Parth| 14600|\n",
      "|  4|  Rishabh| 20500|\n",
      "|  5|    Daisy| 34000|\n",
      "|  6|    Annie| 23000|\n",
      "|  7| Sushmita| 50000|\n",
      "|  8| Kaivalya| 20000|\n",
      "|  9|    Varun| 70000|\n",
      "| 10|Shambhavi| 21500|\n",
      "| 11|  Johnson| 25500|\n",
      "| 12|     Riya| 17000|\n",
      "| 13|    Krish| 17000|\n",
      "| 14| Akanksha| 20000|\n",
      "| 15|   Rutuja| 21000|\n",
      "+---+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     _corrupt_record|\n",
      "+--------------------+\n",
      "|                   {|\n",
      "|    \"fruit\": \"App...|\n",
      "|    \"size\": \"Large\",|\n",
      "|      \"color\": \"Red\"|\n",
      "|                   }|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demo=sqlContext.read.json(\"hdfs://nameservice1/user/edureka_294428/demo.json\")\n",
    "demo.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Salary: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|Salary|\n",
      "+------+\n",
      "| 20000|\n",
      "| 15000|\n",
      "| 14600|\n",
      "| 20500|\n",
      "| 34000|\n",
      "| 23000|\n",
      "| 50000|\n",
      "| 20000|\n",
      "| 70000|\n",
      "| 21500|\n",
      "| 25500|\n",
      "| 17000|\n",
      "| 17000|\n",
      "| 20000|\n",
      "| 21000|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+\n",
      "|     Name|(Salary + 10)|\n",
      "+---------+-------------+\n",
      "|     John|        20010|\n",
      "|    Rohit|        15010|\n",
      "|    Parth|        14610|\n",
      "|  Rishabh|        20510|\n",
      "|    Daisy|        34010|\n",
      "|    Annie|        23010|\n",
      "| Sushmita|        50010|\n",
      "| Kaivalya|        20010|\n",
      "|    Varun|        70010|\n",
      "|Shambhavi|        21510|\n",
      "|  Johnson|        25510|\n",
      "|     Riya|        17010|\n",
      "|    Krish|        17010|\n",
      "| Akanksha|        20010|\n",
      "|   Rutuja|        21010|\n",
      "+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(employee_df['Name'], employee_df['Salary'] + 10).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+\n",
      "| ID|     Name|Salary|\n",
      "+---+---------+------+\n",
      "| 10|Shambhavi| 21500|\n",
      "| 11|  Johnson| 25500|\n",
      "| 12|     Riya| 17000|\n",
      "| 13|    Krish| 17000|\n",
      "| 14| Akanksha| 20000|\n",
      "| 15|   Rutuja| 21000|\n",
      "+---+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.filter(employee_df['ID'] > 9).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|Salary|count|\n",
      "+------+-----+\n",
      "| 21000|    1|\n",
      "| 21500|    1|\n",
      "| 14600|    1|\n",
      "| 23000|    1|\n",
      "| 25500|    1|\n",
      "| 34000|    1|\n",
      "| 20000|    3|\n",
      "| 70000|    1|\n",
      "| 17000|    2|\n",
      "| 15000|    1|\n",
      "| 20500|    1|\n",
      "| 50000|    1|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.groupBy(\"Salary\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+\n",
      "| ID|     Name|Salary|\n",
      "+---+---------+------+\n",
      "|  1|     John| 20000|\n",
      "|  2|    Rohit| 15000|\n",
      "|  3|    Parth| 14600|\n",
      "|  4|  Rishabh| 20500|\n",
      "|  5|    Daisy| 34000|\n",
      "|  6|    Annie| 23000|\n",
      "|  7| Sushmita| 50000|\n",
      "|  8| Kaivalya| 20000|\n",
      "|  9|    Varun| 70000|\n",
      "| 10|Shambhavi| 21500|\n",
      "| 11|  Johnson| 25500|\n",
      "| 12|     Riya| 17000|\n",
      "| 13|    Krish| 17000|\n",
      "| 14| Akanksha| 20000|\n",
      "| 15|   Rutuja| 21000|\n",
      "+---+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_df.createOrReplaceTempView(\"EMP\")\n",
    "sqlDF = sqlContext.sql(\"SELECT * FROM EMP\")\n",
    "sqlDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peopleDF=sqlContext.read.json(\"hdfs://nameservice1/user/edureka_294428/people.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleDF.write.parquet(\"hdfs://nameservice1/user/edureka_294428/people3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parquetFile=sqlContext.read.parquet(\"people3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquetFile.createOrReplaceTempView('parquetFile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teenagers=sqlContext.sql(\"SELECT name FROM parquetFile WHERE age>=13 AND age<=19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  name|\n",
      "+------+\n",
      "|justin|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "teenagers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "peopleDF = sqlContext.read.json(\"hdfs://nameservice1/user/edureka_294428/people.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sqlContext.registerFunction(\"uppercase\", lambda x:x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "peopleDF.createOrReplaceTempView(\"PEP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newRDD=sqlContext.sql(\"SELECT uppercase(name) FROM PEP WHERE age>20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|uppercase(name)|\n",
      "+---------------+\n",
      "|        MICHAEL|\n",
      "|           ANDY|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newRDD.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
