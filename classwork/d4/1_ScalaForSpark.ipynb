{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "println(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[merrywivesofwindsor, twelfthnight, midsummersnightsdream, loveslabourslost, asyoulikeit, comedyoferrors, muchadoaboutnothing, tamingoftheshrew]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new java.io.File(\"/data/shakespeare\").list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scala для Spark (и этого достаточно)\n",
    "\n",
    "\n",
    "[Scala](http://scala-lang.org) обязательный инструмент для больших данных, особенно для [Apache Spark's](http://spark.apache.org) Scala API в Spark создает более явные и простые конструкции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Почему Scala?\n",
    "\n",
    "4 пункта за Scala:\n",
    "* **Performance:** Spark написан на Scala, основное API написано для Scala, то есть самое полное и содержательное API, особенно для [RDD](http://spark.apache.org/docs/latest/programming-guide.html#resilient-distributed-datasets-rdds). Spark на Scala исключает шаги по переводу Python кода для JVM.\n",
    "* **Debugging:** Ошибки Runtime и общее понимание ошибок проще, когда вы знакомы со Scala, так как информация из debugger приходит в виде Scala Exception.\n",
    "* **Concise, Expressive Code:** Решения на Scala более короткие и локаничные (особено, по сравнению с Java). На Scala вы будете более продуктивны.\n",
    "* **Type Safety:** Есть статическая типизация, что не позволяет не совершать ошибок и не получать не ожиданных результатов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### У Scala есть минусы?\n",
    "\n",
    "В Scala есть минусы (особенно, если очень плохо с функциональным программированием и понимание [жаргона](https://github.com/hemanth/functional-programming-jargon)):\n",
    "* **Libraries:** Scala не так богата библиотеками, как Python.\n",
    "* **Advanced Language Features:** В Scala много особенностей, которые можно не знать и из-за этого не использовать.\n",
    "\n",
    "\n",
    "**! Note:** всегда можно научится функциональному программированию. [Всё о ФП](https://github.com/xgrommx/awesome-functional-programming#tutorials-and-articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Материалы, которые вам помогут\n",
    "\n",
    "* [Programming Scala, Second Edition](http://shop.oreilly.com/product/0636920033073.do)\n",
    "* [Scala Language Website](http://scala-lang.org/)\n",
    "\n",
    "* Scaladocs для <a href=\"http://www.scala-lang.org/api/current/#package\" target=\"scala_scaladocs\">Scala</a>.\n",
    "* Scaladocs для <a href=\"http://spark.apache.org/docs/latest/api/scala/index.html#package\" target=\"spark_scaladocs\">Spark</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рабочая среда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types will be printed.\n"
     ]
    }
   ],
   "source": [
    "// конфигурирование среды для настройки типов (всегда отображать)\n",
    "%showTypes on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[SparkContext](http://spark.apache.org/docs/latest/programming-guide.html#initializing-spark) - это точка входа (первый шаг работы) в среде Spark, даже если вы работаете с `SparkSession`. \n",
    "\n",
    "Вы указываете: где ваш кластре, какая его конфигурация и с какими настройками мы будем рабоать.\n",
    "\n",
    "Часто перемунню, где вызывают `SparkContext` называют `sc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul>\n",
       "<li><a href=\"Some(http://638dd926b4fa:4040)\" target=\"new_tab\">Spark UI: local-1529932883293</a></li>\n",
       "</ul>"
      ],
      "text/plain": [
       "Spark local-1529932883293: Some(http://638dd926b4fa:4040)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version:      2.3.0\n",
      "Spark master:       local[*]\n",
      "Running 'locally'?: true\n"
     ]
    }
   ],
   "source": [
    "println(\"Spark version:      \" + sc.version)\n",
    "println(\"Spark master:       \" + sc.master)\n",
    "println(\"Running 'locally'?: \" + sc.isLocal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изучение Scala через работу со Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \"method\" vs. \"function\"  (чем отличается?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем погружение в синтаксис Scala на примере функции, которая выводить информационное сообщение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "info: (message: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/*\n",
    " * \"info\" принимает String аргумент и печатает строку, которую она получила\n",
    " */\n",
    "def info(message: String): String = {\n",
    "    println(message)\n",
    "\n",
    "    // последняя строка функции - это то, что будет она взвращать\n",
    "    // \"return\" не обязательное слово\n",
    "    message  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error: (message: String)String\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "/*\n",
    " * \"error\" принимает String аргумент и печатает строку\n",
    " */\n",
    "def error(message: String): String = {   \n",
    "    \n",
    "    val fullMessage = s\"\"\"\n",
    "        |********************************************************************\n",
    "        |\n",
    "        |  ERROR: $message\n",
    "        |\n",
    "        |********************************************************************\n",
    "        |\"\"\".stripMargin\n",
    "    println(fullMessage)\n",
    "    \n",
    "    fullMessage\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is well.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "infoString = All is well.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "All is well."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val infoString = info(\"All is well.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********************************************************************\n",
      "\n",
      "  ERROR: Uh oh...\n",
      "\n",
      "********************************************************************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "errorString = \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "********************************************************************\n",
       "\n",
       "  ERROR: Uh oh...\n",
       "\n",
       "********************************************************************\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val errorString = error(\"Uh oh...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "********************************************************************\n",
       "\n",
       "  ERROR: Uh oh...\n",
       "\n",
       "********************************************************************\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorString"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "в Scala есть особенное и интересное форматирование строк:\n",
    "\n",
    "* **Тройные кавычки:** `\"\"\"...\"\"\"` - для многострочного сообщения\n",
    "* **Строка с возмжожностью форматирования (с переменными):** `s` в самом начале, перед кавычками, `s\"...\"` или `s\"\"\"...\"\"\"`, позволит вам использовать переменные из среды прямо в предложениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Use braces for expressions: 2.3.0.\n",
       "You can omit the braces when just using a variable: org.apache.spark.SparkContext@3ca367f9\n",
       "However, watch for ambiguities like org.apache.spark.SparkContext@3ca367f9andextrastuff"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"\"\"Use braces for expressions: ${sc.version}.\n",
    "You can omit the braces when just using a variable: $sc\n",
    "However, watch for ambiguities like ${sc}andextrastuff\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`stripMargin` - методл для управлениями проблемами в строке. Если в строку `|`, то вы можете указывать на количество пробелов перед текстом, относительно левого края."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\n",
       "\"\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "line 1\n",
       "  line 2\n",
       "  line 3\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"\"\"\n",
    "    |line 1\n",
    "    |  line 2\n",
    "    |  |  line 3\n",
    "    |\"\"\".stripMargin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutable Variables (Var) vs. Immutable Values (Val)\n",
    "\n",
    "* `val immutableValue = ...` - переменная, которую нельзя перезаписать, то есть это `immutableValue` (рекомендуемый вариант)\n",
    "* `var mutableVariable = ...` - обычный тип переменных, которые можно перезаписывать, так как вы привыкли в Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как Scala компилируется в JVM, то мы можем использовать общие переменные и библиотеки.\n",
    "\n",
    "Для работы с файлами (для чтения и записи) мы будем использовать библиотеку [java.lang.String](https://docs.oracle.com/javase/8/docs/api/java/lang/String.html) и [java.io.File](https://docs.oracle.com/javase/8/docs/api/java/io/File.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.io.File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val shakespeare = new File(\"/data/shakespeare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Scala `if` конструкция - это выражние на результат True или False (в Java / Python - это условные конструкции).\n",
    "\n",
    "То есть, если `if` условие возвращает `true` или `false`, то результат возвращается в `success` переменную, которую мы можем сразу использовать далее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val success = if (shakespeare.exists == false) {   // doesn't exist already?\n",
    "    error(s\"Data directory path doesn't exist! $shakespeare\")  // ignore returned string\n",
    "    false\n",
    "} else {\n",
    "    info(s\"$shakespeare exists\")\n",
    "    true\n",
    "}\n",
    "println(\"success = \" + success)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pathSeparator = File.separator\n",
    "val targetDirName = shakespeare.toString\n",
    "val plays = Seq(\n",
    "    \"tamingoftheshrew\", \"comedyoferrors\", \"loveslabourslost\", \"midsummersnightsdream\",\n",
    "    \"merrywivesofwindsor\", \"muchadoaboutnothing\", \"asyoulikeit\", \"twelfthnight\")\n",
    "\n",
    "if (success) {\n",
    "    println(s\"Checking that the plays are in $shakespeare:\")\n",
    "    val failures = for {\n",
    "        // for play in plays\n",
    "        play <- plays\n",
    "        \n",
    "        // создаем строку\n",
    "        playFileName = targetDirName + pathSeparator + play\n",
    "        \n",
    "        // чтение файла\n",
    "        playFile = new File(playFileName)\n",
    "        if (playFile.exists == false)\n",
    "    } yield {\n",
    "        s\"$playFileName:\\tNOT FOUND!\"\n",
    "    }\n",
    "  \n",
    "    println(\"Finished!\")\n",
    "    if (failures.size == 0) {\n",
    "        info(\"All plays found!\")\n",
    "    } else {\n",
    "        println(\"The following expected plays were not found:\")\n",
    "        failures.foreach(play => error(play))\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции, как аргументы\n",
    "\n",
    "Сделаем разбор на примере `collection.foreach(println)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass println as the function to use for each element:\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n",
      "\n",
      "Using an anonymous function that calls println: `str => println(str)`\n",
      "(Note that the type of the argument `str` is inferred to be String.)\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n",
      "\n",
      "Adding the argument type explicitly. Note that the parentheses are required.\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n",
      "\n",
      "Why do we need to name this argument? Scala lets us use _ as a placeholder.\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n",
      "\n",
      "For longer functions, you can use {...} instead of (...).\n",
      "Why? Because it gives you the familiar multiline block syntax with {...}\n",
      "tamingoftheshrew\n",
      "comedyoferrors\n",
      "loveslabourslost\n",
      "midsummersnightsdream\n",
      "merrywivesofwindsor\n",
      "muchadoaboutnothing\n",
      "asyoulikeit\n",
      "twelfthnight\n",
      "\n",
      "The _ placeholder can be used *once* for each argument in the list.\n",
      "As an assume, use `reduceLeft` to sum some integers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "integers = Range(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "println(\"Pass println as the function to use for each element:\")\n",
    "plays.foreach(println)\n",
    "\n",
    "println(\"\\nUsing an anonymous function that calls println: `str => println(str)`\")\n",
    "println(\"(Note that the type of the argument `str` is inferred to be String.)\")\n",
    "plays.foreach(str => println(str))\n",
    "\n",
    "println(\"\\nAdding the argument type explicitly. Note that the parentheses are required.\")\n",
    "plays.foreach((str: String) => println(str))\n",
    "\n",
    "println(\"\\nWhy do we need to name this argument? Scala lets us use _ as a placeholder.\")\n",
    "plays.foreach(println(_))\n",
    "\n",
    "println(\"\\nFor longer functions, you can use {...} instead of (...).\")\n",
    "println(\"Why? Because it gives you the familiar multiline block syntax with {...}\")\n",
    "plays.foreach {\n",
    "  (str: String) => println(str)\n",
    "}\n",
    "\n",
    "println(\"\\nThe _ placeholder can be used *once* for each argument in the list.\")\n",
    "println(\"As an assume, use `reduceLeft` to sum some integers.\")\n",
    "val integers = 0 to 10   // python range\n",
    "integers.reduceLeft((i,j) => i+j)\n",
    "integers.reduceLeft(_+_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted Index\n",
    "\n",
    "\n",
    "Inverted Index - это очень сложный процесс, когда вы \"проходитесь\" по всему корпусу документов, токенизируете слова и возвращаете список слов и индекс. Это подобие word count, но более сложное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iiFirstPass1 = MapPartitionsRDD[9] at mapValues at <console>:44\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[9] at mapValues at <console>:44"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val iiFirstPass1 = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap { location_contents_tuple2 =>     // применяем функцию, которая создает pair rdd (слово, документ)\n",
    "        val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")\n",
    "        val fileName = location_contents_tuple2._1.split(pathSeparator).last\n",
    "        words.map(word => ((word, fileName), 1))\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { word_file_count_tup3 => \n",
    "        (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    mapValues { iterable => \n",
    "        val vect = iterable.toVector.sortBy { file_count_tup2 => \n",
    "                  (-file_count_tup2._2, file_count_tup2._1)\n",
    "        }\n",
    "        vect.mkString(\",\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем пошаговый разбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fileContents = sc.wholeTextFiles(shakespeare.toString)\n",
    "fileContents   //"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(foo,101,3.14159,(bar,202))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// сделаем разбор типов (особенно вложенных (\"bar\", 202L))\n",
    "(\"foo\", 101, 3.14159, (\"bar\", 202L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Токенизация\n",
    "\n",
    "> **Note:**  \"tokenization\", в данном примере очень простая, мы не делаем \"глубокое очищение слов\". Так как токенизация - это основной элемент процесса _natural language processing_ (NLP), то нужно будет отдельно узнать, как правильно сделать слова \"чистыми\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordFileNameOnes = MapPartitionsRDD[12] at flatMap at <console>:34\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[12] at flatMap at <console>:34"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordFileNameOnes = fileContents.flatMap { location_contents_tuple2 => \n",
    "    // record: (file_path, \"all the words in the file\")\n",
    "    // mytuple._2 => дай мне только второй элемент\n",
    "    val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")              \n",
    "    // mytuple._1 => дай мне только первый элемент\n",
    "    val fileName = location_contents_tuple2._1.split(pathSeparator).last  \n",
    "    // создаем новый кортеж  и подставляем базовое числов для счета\n",
    "    words.map(word => ((word, fileName), 1))\n",
    "}\n",
    "wordFileNameOnes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры использования\n",
    "\n",
    "`argument_list => body`:\n",
    "\n",
    "```scala\n",
    "location_contents_tuple2 => \n",
    "    val words = ...\n",
    "    ...\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "```scala\n",
    "(some_tuple3: (String,Int,Double)) => ...\n",
    "(arg1, arg2, arg3) => ...\n",
    "(arg1: String, arg2: Int, arg3: Double) => ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее про `location_contents_tuple2`\n",
    "\n",
    "Мы берем `первый` элемент `_1` и `второй` способом `_2` (в Python [n])\n",
    "\n",
    "\n",
    "```scala\n",
    "val words = location_contents_tuple2._2.split(\"\"\"\\W+\"\"\")\n",
    "```\n",
    "\n",
    "Если известно, что элемент последний, то можно использовать метод `.last`\n",
    "\n",
    "```scala\n",
    "val fileName = location_contents_tuple2._1.split(pathSeparator).last\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173336"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordFileNameOnes.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((,merrywivesofwindsor),1)\n",
      "((THE,merrywivesofwindsor),1)\n",
      "((MERRY,merrywivesofwindsor),1)\n",
      "((WIVES,merrywivesofwindsor),1)\n",
      "((OF,merrywivesofwindsor),1)\n",
      "((WINDSOR,merrywivesofwindsor),1)\n",
      "((DRAMATIS,merrywivesofwindsor),1)\n",
      "((PERSONAE,merrywivesofwindsor),1)\n",
      "((SIR,merrywivesofwindsor),1)\n",
      "((JOHN,merrywivesofwindsor),1)\n"
     ]
    }
   ],
   "source": [
    "wordFileNameOnes.take(10).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сделаем отбор уникальных пар `(word,fileName)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uniques = ShuffledRDD[13] at reduceByKey at <console>:36\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[13] at reduceByKey at <console>:36"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val uniques = wordFileNameOnes.reduceByKey((count1, count2) => count1 + count2)\n",
    "uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27276"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniques.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((dexterity,merrywivesofwindsor),1)\n",
      "((force,muchadoaboutnothing),2)\n",
      "((whole,comedyoferrors),2)\n",
      "((lamb,muchadoaboutnothing),2)\n",
      "((blunt,tamingoftheshrew),3)\n",
      "((letter,merrywivesofwindsor),19)\n",
      "((crest,asyoulikeit),1)\n",
      "((bestow,asyoulikeit),1)\n",
      "((rear,midsummersnightsdream),1)\n",
      "((crossing,tamingoftheshrew),1)\n",
      "((wronged,merrywivesofwindsor),4)\n",
      "((S,tamingoftheshrew),10)\n",
      "((HIPPOLYTA,midsummersnightsdream),19)\n",
      "((revolve,twelfthnight),1)\n",
      "((er,merrywivesofwindsor),11)\n",
      "((renown,asyoulikeit),1)\n",
      "((cubiculo,twelfthnight),1)\n",
      "((All,twelfthnight),3)\n",
      "((power,loveslabourslost),8)\n",
      "((Albeit,asyoulikeit),1)\n",
      "((lips,tamingoftheshrew),3)\n",
      "((upshot,twelfthnight),1)\n",
      "((approach,midsummersnightsdream),4)\n",
      "((mean,muchadoaboutnothing),5)\n",
      "((embossed,asyoulikeit),1)\n",
      "((varnish,loveslabourslost),2)\n",
      "((Apollo,midsummersnightsdream),1)\n",
      "((spangled,midsummersnightsdream),1)\n",
      "((gentlemen,comedyoferrors),1)\n",
      "((Rebuke,loveslabourslost),1)\n"
     ]
    }
   ],
   "source": [
    "uniques.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_inverted index_ подразуменвает группировку по слову и файл `((word,fileName),count)`, но счет должен быть по конкретному документу `(word,(fileName,count))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words = MapPartitionsRDD[14] at map at <console>:38\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[14] at map at <console>:38"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val words = uniques.map { word_file_count_tup3 => \n",
    "    (word_file_count_tup3._1._1, (word_file_count_tup3._1._2, word_file_count_tup3._2)) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "wordGroups = ShuffledRDD[18] at sortByKey at <console>:40\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[18] at sortByKey at <console>:40"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wordGroups = words.groupByKey.sortByKey(ascending = true)\n",
    "wordGroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11951"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordGroups.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,CompactBuffer((tamingoftheshrew,1), (asyoulikeit,1), (merrywivesofwindsor,1), (comedyoferrors,1), (midsummersnightsdream,1), (twelfthnight,1), (loveslabourslost,1), (muchadoaboutnothing,1)))\n",
      "(A,CompactBuffer((loveslabourslost,78), (midsummersnightsdream,39), (muchadoaboutnothing,31), (merrywivesofwindsor,38), (comedyoferrors,42), (asyoulikeit,34), (twelfthnight,47), (tamingoftheshrew,59)))\n",
      "(ABOUT,CompactBuffer((muchadoaboutnothing,18)))\n",
      "(ACT,CompactBuffer((asyoulikeit,22), (comedyoferrors,11), (tamingoftheshrew,12), (loveslabourslost,9), (muchadoaboutnothing,17), (twelfthnight,18), (merrywivesofwindsor,23), (midsummersnightsdream,9)))\n",
      "(ADAM,CompactBuffer((asyoulikeit,16)))\n",
      "(ADO,CompactBuffer((muchadoaboutnothing,18)))\n",
      "(ADRIANA,CompactBuffer((comedyoferrors,85)))\n",
      "(ADRIANO,CompactBuffer((loveslabourslost,111)))\n",
      "(AEGEON,CompactBuffer((comedyoferrors,20)))\n",
      "(AEMELIA,CompactBuffer((comedyoferrors,16)))\n",
      "(AEMILIA,CompactBuffer((comedyoferrors,3)))\n",
      "(AEacides,CompactBuffer((tamingoftheshrew,1)))\n",
      "(AEgeon,CompactBuffer((comedyoferrors,7)))\n",
      "(AEgle,CompactBuffer((midsummersnightsdream,1)))\n",
      "(AEmilia,CompactBuffer((comedyoferrors,4)))\n",
      "(AEsculapius,CompactBuffer((merrywivesofwindsor,1)))\n",
      "(AGUECHEEK,CompactBuffer((twelfthnight,2)))\n",
      "(ALL,CompactBuffer((midsummersnightsdream,2), (tamingoftheshrew,2)))\n",
      "(AMIENS,CompactBuffer((asyoulikeit,16)))\n",
      "(ANDREW,CompactBuffer((twelfthnight,104)))\n",
      "(ANGELO,CompactBuffer((comedyoferrors,36)))\n",
      "(ANN,CompactBuffer((merrywivesofwindsor,1)))\n",
      "(ANNE,CompactBuffer((merrywivesofwindsor,27)))\n",
      "(ANTIPHOLUS,CompactBuffer((comedyoferrors,195)))\n",
      "(ANTONIO,CompactBuffer((muchadoaboutnothing,32), (twelfthnight,32)))\n",
      "(ARMADO,CompactBuffer((loveslabourslost,111)))\n",
      "(AS,CompactBuffer((asyoulikeit,24)))\n",
      "(AUDREY,CompactBuffer((asyoulikeit,18)))\n",
      "(Abate,CompactBuffer((midsummersnightsdream,1), (loveslabourslost,1)))\n",
      "(Abbess,CompactBuffer((comedyoferrors,2)))\n"
     ]
    }
   ],
   "source": [
    "wordGroups.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Scala можно использовать метод [Vector](http://www.scala-lang.org/api/current/index.html#scala.collection.immutable.Vector) для создания объекта (key, [(key,v), (key,v), (key,v)])\n",
    "\n",
    " `-fileNameCountTuple2._2` - только для лучшей сортировки (большие отрицательные значения внизу списка)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iiFirstPass2 = MapPartitionsRDD[19] at mapValues at <console>:42\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[19] at mapValues at <console>:42"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val iiFirstPass2 = wordGroups.mapValues { iterable => \n",
    "    val vect = iterable.toVector.sortBy { file_count_tup2 => \n",
    "        (-file_count_tup2._2, file_count_tup2._1)\n",
    "    }\n",
    "    vect.mkString(\",\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(,(asyoulikeit,1),(comedyoferrors,1),(loveslabourslost,1),(merrywivesofwindsor,1),(midsummersnightsdream,1),(muchadoaboutnothing,1),(tamingoftheshrew,1),(twelfthnight,1))\n",
      "(A,(loveslabourslost,78),(tamingoftheshrew,59),(twelfthnight,47),(comedyoferrors,42),(midsummersnightsdream,39),(merrywivesofwindsor,38),(asyoulikeit,34),(muchadoaboutnothing,31))\n",
      "(ABOUT,(muchadoaboutnothing,18))\n",
      "(ACT,(merrywivesofwindsor,23),(asyoulikeit,22),(twelfthnight,18),(muchadoaboutnothing,17),(tamingoftheshrew,12),(comedyoferrors,11),(loveslabourslost,9),(midsummersnightsdream,9))\n",
      "(ADAM,(asyoulikeit,16))\n",
      "(ADO,(muchadoaboutnothing,18))\n",
      "(ADRIANA,(comedyoferrors,85))\n",
      "(ADRIANO,(loveslabourslost,111))\n",
      "(AEGEON,(comedyoferrors,20))\n",
      "(AEMELIA,(comedyoferrors,16))\n",
      "(AEMILIA,(comedyoferrors,3))\n",
      "(AEacides,(tamingoftheshrew,1))\n",
      "(AEgeon,(comedyoferrors,7))\n",
      "(AEgle,(midsummersnightsdream,1))\n",
      "(AEmilia,(comedyoferrors,4))\n",
      "(AEsculapius,(merrywivesofwindsor,1))\n",
      "(AGUECHEEK,(twelfthnight,2))\n",
      "(ALL,(midsummersnightsdream,2),(tamingoftheshrew,2))\n",
      "(AMIENS,(asyoulikeit,16))\n",
      "(ANDREW,(twelfthnight,104))\n",
      "(ANGELO,(comedyoferrors,36))\n",
      "(ANN,(merrywivesofwindsor,1))\n",
      "(ANNE,(merrywivesofwindsor,27))\n",
      "(ANTIPHOLUS,(comedyoferrors,195))\n",
      "(ANTONIO,(muchadoaboutnothing,32),(twelfthnight,32))\n",
      "(ARMADO,(loveslabourslost,111))\n",
      "(AS,(asyoulikeit,24))\n",
      "(AUDREY,(asyoulikeit,18))\n",
      "(Abate,(loveslabourslost,1),(midsummersnightsdream,1))\n",
      "(Abbess,(comedyoferrors,2))\n"
     ]
    }
   ],
   "source": [
    "iiFirstPass2.take(30).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Matching\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* `filter(word => word.size > 0)` удаляем пустые строки (слова) `// #1`.\n",
    "* `word.toLowerCase` конвертация всех значений в нижний регистр `// #2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ii1 = MapPartitionsRDD[39] at mapValues at <console>:54\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[39] at mapValues at <console>:54"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ii1 = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap {\n",
    "        case (location, contents) => \n",
    "            val words = contents.split(\"\"\"\\W+\"\"\").\n",
    "                filter(word => word.size > 0)                      // #1\n",
    "            val fileName = location.split(pathSeparator).last\n",
    "            words.map(word => ((word.toLowerCase, fileName), 1))   // #2\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { \n",
    "        case ((word, fileName), count) => (word, (fileName, count)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    mapValues { iterable => \n",
    "        val vect = iterable.toVector.sortBy { \n",
    "            case (fileName, count) => (-count, fileName) \n",
    "        }\n",
    "        vect.mkString(\",\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlContext = org.apache.spark.sql.SQLContext@27a9da47\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@27a9da47"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Конвертируем `RDD` в `DataFrame` функцией `sqlContext.createDataFrame` и методом `toDF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ii1DF = [word: string, locations_counts: string]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[word: string, locations_counts: string]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ii1DF = sqlContext.createDataFrame(ii1).toDF(\"word\", \"locations_counts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%%dataframe`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>word</th><th>locations_counts</th></tr><tr><td>a</td><td>(loveslabourslost,507),(merrywivesofwindsor,494),(muchadoaboutnothing,492),(asyoulikeit,461),(tamingoftheshrew,445),(twelfthnight,416),(midsummersnightsdream,281),(comedyoferrors,254)</td></tr><tr><td>abandon</td><td>(asyoulikeit,4),(tamingoftheshrew,1),(twelfthnight,1)</td></tr><tr><td>abate</td><td>(loveslabourslost,1),(midsummersnightsdream,1),(tamingoftheshrew,1)</td></tr><tr><td>abatement</td><td>(twelfthnight,1)</td></tr><tr><td>abbess</td><td>(comedyoferrors,8)</td></tr><tr><td>abbey</td><td>(comedyoferrors,9)</td></tr><tr><td>abbominable</td><td>(loveslabourslost,1)</td></tr><tr><td>abbreviated</td><td>(loveslabourslost,1)</td></tr><tr><td>abed</td><td>(asyoulikeit,1),(twelfthnight,1)</td></tr><tr><td>abetting</td><td>(comedyoferrors,1)</td></tr></table>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dataframe\n",
    "ii1DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ii = MapPartitionsRDD[54] at map at <console>:55\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[54] at map at <console>:55"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// супер правильный вариант\n",
    "val ii = sc.wholeTextFiles(shakespeare.toString).\n",
    "    flatMap {\n",
    "        case (location, contents) => \n",
    "            val words = contents.split(\"\"\"\\W+\"\"\").\n",
    "                filter(word => word.size > 0)                      // #1\n",
    "            val fileName = location.split(pathSeparator).last\n",
    "            words.map(word => ((word.toLowerCase, fileName), 1))   // #2\n",
    "    }.\n",
    "    reduceByKey((count1, count2) => count1 + count2).\n",
    "    map { \n",
    "        case ((word, fileName), count) => (word, (fileName, count)) \n",
    "    }.\n",
    "    groupByKey.\n",
    "    sortByKey(ascending = true).\n",
    "    map {                         \n",
    "      case (word, iterable) =>    \n",
    "\n",
    "        val vect = iterable.toVector.sortBy { \n",
    "            case (fileName, count) => (-count, fileName) \n",
    "        }\n",
    "\n",
    "        // `Vector.unzip` - возвращает каждый элемент в отдельности \n",
    "        val (locations, counts) = vect.unzip  \n",
    "        \n",
    "        // считаем общее кол-во по всем элементам\n",
    "        val totalCount = counts.reduceLeft((n1,n2) => n1+n2)\n",
    "        \n",
    "        (word, totalCount, locations, counts)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iiDF = [word: string, total_count: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "warning: there was one deprecation warning; re-run with -deprecation for details\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[word: string, total_count: int ... 2 more fields]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// зарегистрируем, как SQL таблицу\n",
    "val iiDF = sqlContext.createDataFrame(ii).toDF(\"word\", \"total_count\", \"locations\", \"counts\")\n",
    "iiDF.cache\n",
    "iiDF.registerTempTable(\"inverted_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение схемы таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- total_count: integer (nullable = false)\n",
      " |-- locations: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- counts: array (nullable = true)\n",
      " |    |-- element: integer (containsNull = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iiDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "+-----------+-----------+--...\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "+-----------+-----------+----------------+---------+\n",
       "|       word|total_count|    top_location|top_count|\n",
       "+-----------+-----------+----------------+---------+\n",
       "|          a|       3350|loveslabourslost|      507|\n",
       "|    abandon|          6|     asyoulikeit|        4|\n",
       "|      abate|          3|loveslabourslost|        1|\n",
       "|  abatement|          1|    twelfthnight|        1|\n",
       "|     abbess|          8|  comedyoferrors|        8|\n",
       "|      abbey|          9|  comedyoferrors|        9|\n",
       "|abbominable|          1|loveslabourslost|        1|\n",
       "|abbreviated|          1|loveslabourslost|        1|\n",
       "|       abed|          2|     asyoulikeit|        1|\n",
       "|   abetting|          1|  comedyoferrors|        1|\n",
       "+-----------+-----------+----------------+---------+\n",
       "only showing top 10 rows\n",
       "\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%SQL\n",
    "SELECT word, total_count, locations[0] AS top_location, counts[0] AS top_count \n",
    "FROM inverted_index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%%SQL` не содержит возможностей конфигурации, но `%%DataFrame` имеет некоторые опции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "%%dataframe [arguments]\n",
       "DATAFRAME_CODE\n",
       "\n",
       "DATAFRAME_CODE can be any numbered lines of code, as long as the\n",
       "last line is a reference to a variable which is a DataFrame.\n",
       "    Option    Description                       \n",
       "------    -----------                       \n",
       "--limit   The number of records to return   \n",
       "            (default: 10)                   \n",
       "--output  The type of the output: html, csv,\n",
       "            json (default: html)            \n"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WHERE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topLocations = [word: string, total_count: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[word: string, total_count: int ... 2 more fields]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val topLocations = sqlContext.sql(\"\"\"\n",
    "    SELECT word,  total_count, locations[0] AS top_location, counts[0] AS top_count\n",
    "    FROM inverted_index \n",
    "    WHERE word LIKE '%love%' OR word LIKE '%hate%'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`%%dataframe` _magic_ с опциями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><th>word</th><th>total_count</th><th>top_location</th><th>top_count</th></tr><tr><td>beloved</td><td>11</td><td>tamingoftheshrew</td><td>4</td></tr><tr><td>cloven</td><td>1</td><td>loveslabourslost</td><td>1</td></tr><tr><td>cloves</td><td>1</td><td>loveslabourslost</td><td>1</td></tr><tr><td>glove</td><td>3</td><td>loveslabourslost</td><td>2</td></tr><tr><td>glover</td><td>1</td><td>merrywivesofwindsor</td><td>1</td></tr><tr><td>gloves</td><td>5</td><td>merrywivesofwindsor</td><td>3</td></tr><tr><td>hate</td><td>22</td><td>midsummersnightsdream</td><td>9</td></tr><tr><td>hated</td><td>6</td><td>midsummersnightsdream</td><td>4</td></tr><tr><td>hateful</td><td>5</td><td>midsummersnightsdream</td><td>3</td></tr><tr><td>hates</td><td>5</td><td>asyoulikeit</td><td>2</td></tr><tr><td>hateth</td><td>1</td><td>midsummersnightsdream</td><td>1</td></tr><tr><td>love</td><td>662</td><td>loveslabourslost</td><td>121</td></tr><tr><td>loved</td><td>38</td><td>asyoulikeit</td><td>13</td></tr><tr><td>lovely</td><td>15</td><td>midsummersnightsdream</td><td>7</td></tr><tr><td>lover</td><td>33</td><td>asyoulikeit</td><td>14</td></tr><tr><td>lovers</td><td>31</td><td>midsummersnightsdream</td><td>17</td></tr><tr><td>loves</td><td>51</td><td>muchadoaboutnothing</td><td>10</td></tr><tr><td>lovest</td><td>8</td><td>tamingoftheshrew</td><td>3</td></tr><tr><td>loveth</td><td>2</td><td>loveslabourslost</td><td>1</td></tr><tr><td>unloved</td><td>1</td><td>midsummersnightsdream</td><td>1</td></tr><tr><td>whate</td><td>4</td><td>tamingoftheshrew</td><td>3</td></tr><tr><td>whatever</td><td>1</td><td>tamingoftheshrew</td><td>1</td></tr></table>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%dataframe --limit 100\n",
    "topLocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also a useful `show` method on `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+--------------------+---------+\n",
      "|   word|total_count|        top_location|top_count|\n",
      "+-------+-----------+--------------------+---------+\n",
      "|beloved|         11|    tamingoftheshrew|        4|\n",
      "| cloven|          1|    loveslabourslost|        1|\n",
      "| cloves|          1|    loveslabourslost|        1|\n",
      "|  glove|          3|    loveslabourslost|        2|\n",
      "| glover|          1| merrywivesofwindsor|        1|\n",
      "| gloves|          5| merrywivesofwindsor|        3|\n",
      "|   hate|         22|midsummersnightsd...|        9|\n",
      "|  hated|          6|midsummersnightsd...|        4|\n",
      "|hateful|          5|midsummersnightsd...|        3|\n",
      "|  hates|          5|         asyoulikeit|        2|\n",
      "| hateth|          1|midsummersnightsd...|        1|\n",
      "|   love|        662|    loveslabourslost|      121|\n",
      "|  loved|         38|         asyoulikeit|       13|\n",
      "| lovely|         15|midsummersnightsd...|        7|\n",
      "|  lover|         33|         asyoulikeit|       14|\n",
      "| lovers|         31|midsummersnightsd...|       17|\n",
      "|  loves|         51| muchadoaboutnothing|       10|\n",
      "| lovest|          8|    tamingoftheshrew|        3|\n",
      "| loveth|          2|    loveslabourslost|        1|\n",
      "|unloved|          1|midsummersnightsd...|        1|\n",
      "+-------+-----------+--------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topLocations.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+---------------------+---------+\n",
      "|word    |total_count|top_location         |top_count|\n",
      "+--------+-----------+---------------------+---------+\n",
      "|beloved |11         |tamingoftheshrew     |4        |\n",
      "|cloven  |1          |loveslabourslost     |1        |\n",
      "|cloves  |1          |loveslabourslost     |1        |\n",
      "|glove   |3          |loveslabourslost     |2        |\n",
      "|glover  |1          |merrywivesofwindsor  |1        |\n",
      "|gloves  |5          |merrywivesofwindsor  |3        |\n",
      "|hate    |22         |midsummersnightsdream|9        |\n",
      "|hated   |6          |midsummersnightsdream|4        |\n",
      "|hateful |5          |midsummersnightsdream|3        |\n",
      "|hates   |5          |asyoulikeit          |2        |\n",
      "|hateth  |1          |midsummersnightsdream|1        |\n",
      "|love    |662        |loveslabourslost     |121      |\n",
      "|loved   |38         |asyoulikeit          |13       |\n",
      "|lovely  |15         |midsummersnightsdream|7        |\n",
      "|lover   |33         |asyoulikeit          |14       |\n",
      "|lovers  |31         |midsummersnightsdream|17       |\n",
      "|loves   |51         |muchadoaboutnothing  |10       |\n",
      "|lovest  |8          |tamingoftheshrew     |3        |\n",
      "|loveth  |2          |loveslabourslost     |1        |\n",
      "|unloved |1          |midsummersnightsdream|1        |\n",
      "|whate   |4          |tamingoftheshrew     |3        |\n",
      "|whatever|1          |tamingoftheshrew     |1        |\n",
      "+--------+-----------+---------------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topLocations.show(numRows = 40, truncate = false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Самостоятельное задание:** \n",
    "\n",
    "\n",
    "* Найдите слова `glove`, `gloves`, `whate` и `whatever` и найдите документ, где они чаще всего встречаются и кол-во упоминаний\n",
    "* Ваш запрос должен возвращать колонки word, total_count, top_location,\ttop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+\n",
      "|word       |total_count|locations                                                                                                                                       |counts                                  |\n",
      "+-----------+-----------+------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+\n",
      "|a          |3350       |[loveslabourslost, merrywivesofwindsor, muchadoaboutnothing, asyoulikeit, tamingoftheshrew, twelfthnight, midsummersnightsdream, comedyoferrors]|[507, 494, 492, 461, 445, 416, 281, 254]|\n",
      "|abandon    |6          |[asyoulikeit, tamingoftheshrew, twelfthnight]                                                                                                   |[4, 1, 1]                               |\n",
      "|abate      |3          |[loveslabourslost, midsummersnightsdream, tamingoftheshrew]                                                                                     |[1, 1, 1]                               |\n",
      "|abatement  |1          |[twelfthnight]                                                                                                                                  |[1]                                     |\n",
      "|abbess     |8          |[comedyoferrors]                                                                                                                                |[8]                                     |\n",
      "|abbey      |9          |[comedyoferrors]                                                                                                                                |[9]                                     |\n",
      "|abbominable|1          |[loveslabourslost]                                                                                                                              |[1]                                     |\n",
      "|abbreviated|1          |[loveslabourslost]                                                                                                                              |[1]                                     |\n",
      "|abed       |2          |[asyoulikeit, twelfthnight]                                                                                                                     |[1, 1]                                  |\n",
      "|abetting   |1          |[comedyoferrors]                                                                                                                                |[1]                                     |\n",
      "+-----------+-----------+------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sql1 = [word: string, total_count: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[word: string, total_count: int ... 2 more fields]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sql1 = sqlContext.sql(\"\"\"\n",
    "    SELECT * FROM inverted_index\n",
    "\"\"\")\n",
    "sql1.show(10, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Больше о Pattern Matching \n",
    "\n",
    "```scala\n",
    "{\n",
    "    case (location, \"\") => \n",
    "        Array.empty[((String, String), Int)]  // Пустой массив\n",
    "    case (location, contents) => \n",
    "        val words = contents.split(\"\"\"\\W+\"\"\")\n",
    "        val fileName = location.split(pathSep).last\n",
    "        words.map(word => ((word, fileName), 1))\n",
    "}.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found an Int:   1\n",
      "Found a Double: 3.14159\n",
      "Found a Long:   2\n",
      "Found a Float:  4.4\n",
      "Found a two-element tuple with elements of arbitrary type: (one, 1)\n",
      "Found a two-element tuple with elements of arbitrary type: (404.0, boo)\n",
      "Found a three-element tuple with 1st and 3th elements: (11, 12) and 31\n",
      "Found something else: hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stuff = List(1, 3.14159, 2, 4.4, (one,1), (404.0,boo), ((11,12),21,31), hello)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(1, 3.14159, 2, 4.4, (one,1), (404.0,boo), ((11,12),21,31), hello)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stuff = Seq(1, 3.14159, 2L, 4.4F, (\"one\", 1), (404F, \"boo\"), ((11, 12), 21, 31), \"hello\")\n",
    "\n",
    "stuff.foreach {\n",
    "    case i: Int               => println(s\"Found an Int:   $i\")\n",
    "    case l: Long              => println(s\"Found a Long:   $l\")\n",
    "    case f: Float             => println(s\"Found a Float:  $f\")\n",
    "    case d: Double            => println(s\"Found a Double: $d\")\n",
    "    case (x1, x2) => \n",
    "        println(s\"Found a two-element tuple with elements of arbitrary type: ($x1, $x2)\")\n",
    "    case ((x1a, x1b), _, x3) => \n",
    "        println(s\"Found a three-element tuple with 1st and 3th elements: ($x1a, $x1b) and $x3\")\n",
    "    case default              => println(s\"Found something else: $default\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unzip  \n",
    "\n",
    "```scala\n",
    "val (locations, counts) = vect.unzip  \n",
    "```\n",
    "[Vector.unzip](http://www.scala-lang.org/api/current/#scala.collection.immutable.Vector) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A, B, C1, C2, D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "a = A\n",
       "b = B\n",
       "c1 = C1\n",
       "c2 = C2\n",
       "d = D\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "D"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (a, (b, (c1, c2), d)) = (\"A\", (\"B\", (\"C1\", \"C2\"), \"D\"))\n",
    "println(s\" $a, $b, $c1, $c2, $d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala's Object Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes vs. Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class IIRecord1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "hello,3,[one,two],[1,2]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IIRecord1(\n",
    "    word: String, \n",
    "    total_count: Int, \n",
    "    locations: Array[String], \n",
    "    counts: Array[Int]) {\n",
    "    \n",
    "    /** CSV formatted string */\n",
    "    override def toString: String = {\n",
    "        val locStr = locations.mkString(\"[\", \",\", \"]\")  // i.e., \"[a,b,c]\"\n",
    "        val cntStr = counts.mkString(\"[\", \",\", \"]\")  // i.e., \"[1,2,3]\"\n",
    "        s\"$word,$total_count,$locStr,$cntStr\"\n",
    "    }\n",
    "}\n",
    "\n",
    "new IIRecord1(\"hello\", 3, Array(\"one\", \"two\"), Array(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object MySparkJob\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "object MySparkJob {\n",
    "\n",
    "    val greeting = \"Hello Spark!\"\n",
    "    \n",
    "    def main(arguments: Array[String]) = {\n",
    "        println(greeting)\n",
    "        \n",
    "        // Create your SparkContext, etc., etc.\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class IIRecord\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "case class IIRecord(\n",
    "    word: String, \n",
    "    total_count: Int = 0, \n",
    "    locations: Array[String] = Array.empty, \n",
    "    counts: Array[Int] = Array.empty) {\n",
    "\n",
    "    /** \n",
    "     * toCSV.\n",
    "     * Array.toString\n",
    "     */\n",
    "    override def toString: String = \n",
    "        s\"\"\"IIRecord($word, $total_count, $locStr, $cntStr)\"\"\"\n",
    "    \n",
    "    /** CSV-formatted string*/\n",
    "    def toCSV: String = \n",
    "        s\"$word,$total_count,$locStr,$cntStr\"\n",
    "        \n",
    "    /** Return SON-formatted string */\n",
    "    def toJSONString: String = \n",
    "        s\"\"\"{\n",
    "        |  \"word\":        \"$word\", \n",
    "        |  \"total_count\": $total_count, \n",
    "        |  \"locations\":   ${toJSONArrayString(locations)},\n",
    "        |  \"counts\"       ${toArrayString(counts, \", \")}\n",
    "        |}\n",
    "        |\"\"\".stripMargin\n",
    "\n",
    "    private def locStr = toArrayString(locations)\n",
    "    private def cntStr = toArrayString(counts)\n",
    "\n",
    "    // \"[_]\" - означает, что не имеет значения, какой элемент;\n",
    "    private def toArrayString(array: Array[_], delim: String = \",\"): String = \n",
    "        array.mkString(\"[\", delim, \"]\")  // \"[a,b,c]\"\n",
    "\n",
    "    private def toJSONArrayString(array: Array[String]): String =\n",
    "        toArrayString(array.map(quote), \", \")\n",
    "    \n",
    "    private def quote(word: String): String = \"\\\"\" + word + \"\\\"\"  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Применение**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "`toString` output:\n",
      "IIRecord(hello, 0, [], [])\n",
      "IIRecord(world!, 3, [one,two], [1,2])\n",
      "\n",
      "`toJSONString` output:\n",
      "{\n",
      "  \"word\":        \"hello\", \n",
      "  \"total_count\": 0, \n",
      "  \"locations\":   [],\n",
      "  \"counts\"       []\n",
      "}\n",
      "\n",
      "{\n",
      "  \"word\":        \"world!\", \n",
      "  \"total_count\": 3, \n",
      "  \"locations\":   [\"one\", \"two\"],\n",
      "  \"counts\"       [1, 2]\n",
      "}\n",
      "\n",
      "\n",
      "`toCSV` output:\n",
      "hello,0,[],[]\n",
      "world!,3,[one,two],[1,2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hello = IIRecord(hello, 0, [], [])\n",
       "world = IIRecord(world!, 3, [one,two], [1,2])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IIRecord(world!, 3, [one,two], [1,2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hello = new IIRecord(\"hello\")\n",
    "val world = new IIRecord(\"world!\", 3, Array(\"one\", \"two\"), Array(1, 2))\n",
    "\n",
    "println(\"\\n`toString` output:\")\n",
    "println(hello)\n",
    "println(world)\n",
    "\n",
    "println(\"\\n`toJSONString` output:\")\n",
    "println(hello.toJSONString)\n",
    "println(world.toJSONString)\n",
    "\n",
    "println(\"\\n`toCSV` output:\")\n",
    "println(hello.toCSV)\n",
    "println(world.toCSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hello1 = IIRecord(hello1, 0, [], [])\n",
       "hello2 = IIRecord(hello2, 0, [], [])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IIRecord(hello2, 0, [], [])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hello1 = new IIRecord(\"hello1\")\n",
    "val hello2 = IIRecord(\"hello2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hello2b = IIRecord(hello2b, 0, [], [])\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "IIRecord(hello2b, 0, [], [])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val hello2b = IIRecord.apply(\"hello2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and DataFrames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlc = org.apache.spark.sql.SQLContext@27a9da47\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@27a9da47"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlc = sqlContext\n",
    "import sqlc.implicits._   // узнаем об это позже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iiDS = [word: string, total_count: int ... 2 more fields]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[word: string, total_count: int ... 2 more fields]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val iiDS = iiDF.as[IIRecord]\n",
    "iiDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------------+--------------------+\n",
      "|       word|total_count|           locations|              counts|\n",
      "+-----------+-----------+--------------------+--------------------+\n",
      "|          a|       3350|[loveslabourslost...|[507, 494, 492, 4...|\n",
      "|    abandon|          6|[asyoulikeit, tam...|           [4, 1, 1]|\n",
      "|      abate|          3|[loveslabourslost...|           [1, 1, 1]|\n",
      "|  abatement|          1|      [twelfthnight]|                 [1]|\n",
      "|     abbess|          8|    [comedyoferrors]|                 [8]|\n",
      "|      abbey|          9|    [comedyoferrors]|                 [9]|\n",
      "|abbominable|          1|  [loveslabourslost]|                 [1]|\n",
      "|abbreviated|          1|  [loveslabourslost]|                 [1]|\n",
      "|       abed|          2|[asyoulikeit, twe...|              [1, 1]|\n",
      "|   abetting|          1|    [comedyoferrors]|                 [1]|\n",
      "|abhominable|          1|  [loveslabourslost]|                 [1]|\n",
      "|      abhor|          5|[asyoulikeit, com...|     [1, 1, 1, 1, 1]|\n",
      "|     abhors|          2|      [twelfthnight]|                 [2]|\n",
      "|      abide|          5|[merrywivesofwind...|              [3, 2]|\n",
      "|     abides|          1|[muchadoaboutnoth...|                 [1]|\n",
      "|    ability|          2|[muchadoaboutnoth...|              [1, 1]|\n",
      "|     abject|          2|[comedyoferrors, ...|              [1, 1]|\n",
      "|     abjure|          1|[midsummersnights...|                 [1]|\n",
      "|    abjured|          2|[tamingoftheshrew...|              [1, 1]|\n",
      "|       able|          9|[merrywivesofwind...|     [4, 2, 1, 1, 1]|\n",
      "+-----------+-----------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iiDS.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator Syntax\n",
    "\n",
    "Обратим внимание на синтаксис операторов в Scala\n",
    "\n",
    "```scala\n",
    "val m1_times_m2 = m1.*(m2)\n",
    "val m1_times_m2 = m1 * m2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traits\n",
    "_Traits_ == Java 8 _interfaces_ (но DS и Аналитикам это ни чего не говорит). Это объект, который является абстрактным типом, который используется для определения поведения, которое должны реализовывать классы\n",
    "\n",
    "```scala\n",
    "trait Logging {\n",
    "\n",
    "    def log(level: Level, message: String): Unit = logger.log(level, message)\n",
    "    \n",
    "    private logger: Logger = ...\n",
    "}\n",
    "\n",
    "abstract class Service {\n",
    "    def run(): Unit   // No body, so abstract!\n",
    "}\n",
    "\n",
    "class MyService extends Service with Logging {\n",
    "    def run(): Unit = {\n",
    "        log(INFO, \"Staring MyService...\")\n",
    "        ...\n",
    "        log(INFO, \"Finished MyService\")\n",
    "    }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranges\n",
    " [Range](http://www.scala-lang.org/api/current/index.html#scala.collection.immutable.Range), как и в Python range(0, 100), то в Scala => `1 until 100`, `2 to 200 by 3`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Range(1, 2, 3, 4, 5, 6, 7, 8, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 until 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Range(1, 4, 7, 10)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 to 10 by 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,CompactBuffer((7,0), (14,0), (21,0), (28,0), (35,0), (42,0), (49,0)))\n",
      "(1,CompactBuffer((1,1), (8,1), (15,1), (22,1), (29,1), (36,1), (43,1), (50,1)))\n",
      "(2,CompactBuffer((2,2), (9,2), (16,2), (23,2), (30,2), (37,2), (44,2)))\n",
      "(3,CompactBuffer((3,3), (10,3), (17,3), (24,3), (31,3), (38,3), (45,3)))\n",
      "(4,CompactBuffer((4,4), (11,4), (18,4), (25,4), (32,4), (39,4), (46,4)))\n",
      "(5,CompactBuffer((5,5), (12,5), (19,5), (26,5), (33,5), (40,5), (47,5)))\n",
      "(6,CompactBuffer((6,6), (13,6), (20,6), (27,6), (34,6), (41,6), (48,6)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rdd7 = ShuffledRDD[101] at sortByKey at <console>:39\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ShuffledRDD[101] at sortByKey at <console>:39"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// придумаем себе данные на основе range\n",
    "val rdd7 = sc.parallelize(1 to 50).\n",
    "    map(i => (i, i%7)).\n",
    "    groupBy{ case (i, seven) => seven }.\n",
    "    sortByKey()\n",
    "rdd7.take(7).foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример использования\n",
    "\n",
    "```scala\n",
    "(1 to 100)\n",
    ".map(i => i*i)\n",
    "```\n",
    "\n",
    "Создает пользовательность\n",
    "\n",
    "```scala\n",
    "res0: scala.collection.immutable.IndexedSeq[Int] = Vector(1, 4, 9, 16, 25, 36, 49, 64, 81, 100, ...)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scala иерархия типов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Scala Type Hierarchy](http://docs.scala-lang.org/resources/images/classhierarchy.img_assist_custom.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2\n",
      "3\n",
      "None\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "options = List(None, Some(2), Some(3), None, Some(5))\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "List(None, Some(2), Some(3), None, Some(5))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Option - тип с None и каким-то типом данных\n",
    "val options = Seq(None, Some(2), Some(3), None, Some(5))\n",
    "\n",
    "options.foreach { o =>\n",
    "    println(o.getOrElse(\"None\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "2\n",
      "3\n",
      "None\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "options.foreach {\n",
    "    case None    => println(None)\n",
    "    case Some(i) => println(i)  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "// фильтр для None\n",
    "for {\n",
    "    option <- options  \n",
    "    value  <- option   \n",
    "} println(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicits\n",
    "\n",
    "<a name=\"implicits\"></a>\n",
    "\n",
    "`reduceBykey`, `groupByKey` => `*ByKey`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined class Person\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "// Простой класс без `toJSON`:\n",
    "case class Person(name: String, age: Int = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined object implicits\n",
       "p = Person(Dean Wampler,39)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{\"name\": Dean Wampler, \"age\": 39}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// создадим implicits объект\n",
    "object implicits {\n",
    "\n",
    "    // `implicit` - ключевое слово\n",
    "    // На основе класса `Person`, мы создаем класс `PersonToJSONString`,\n",
    "    // который содержит`toJSON`.\n",
    "    implicit class PersonToJSONString(person: Person) {\n",
    "        def toJSON: String = s\"\"\"{\"name\": ${person.name}, \"age\": ${person.age}}\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "import implicits._        //импорт\n",
    "\n",
    "val p = Person(\"Dean Wampler\", 39)\n",
    "\n",
    "// автоматически класс конвертируется в  `PersonToJSONString` и получает метод `toJSON`\n",
    "p.toJSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В Scala это позволяет пробрасывать методы из `RDD` в [DataFrame](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrame) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sqlc = org.apache.spark.sql.SQLContext@27a9da47\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SQLContext@27a9da47"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlc = sqlContext\n",
    "import sqlc.implicits._  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|       word|total_count|\n",
      "+-----------+-----------+\n",
      "|          a|       3350|\n",
      "|    abandon|          6|\n",
      "|      abate|          3|\n",
      "|  abatement|          1|\n",
      "|     abbess|          8|\n",
      "|      abbey|          9|\n",
      "|abbominable|          1|\n",
      "|abbreviated|          1|\n",
      "|       abed|          2|\n",
      "|   abetting|          1|\n",
      "|abhominable|          1|\n",
      "|      abhor|          5|\n",
      "|     abhors|          2|\n",
      "|      abide|          5|\n",
      "|     abides|          1|\n",
      "|    ability|          2|\n",
      "|     abject|          2|\n",
      "|     abjure|          1|\n",
      "|    abjured|          2|\n",
      "|       able|          9|\n",
      "+-----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "wtc = [word: string, total_count: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[word: string, total_count: int]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val wtc = iiDF.select($\"word\", $\"total_count\")\n",
    "wtc.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самое часто использование `implicits` при работе с колонками. `$\"name\"` - это метод в Scale`s\"$foo\"`, но при импорте `import sqlc.implicits._` му можем просто выбирать колонки, а не форматировать строку. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `min`, `max`, `avg`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+------------------+\n",
      "|min(total_count)|max(total_count)|  avg(total_count)|\n",
      "+----------------+----------------+------------------+\n",
      "|               1|            5208|16.651743683350947|\n",
      "+----------------+----------------+------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mma = [min(total_count): int, max(total_count): int ... 1 more field]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[min(total_count): int, max(total_count): int ... 1 more field]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// на примере min, max, avg\n",
    "val mma = iiDF.select(min(\"total_count\"), max(\"total_count\"), avg(\"total_count\"))\n",
    "mma.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
