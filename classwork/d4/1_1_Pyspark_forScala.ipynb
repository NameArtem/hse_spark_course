{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "harmful-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from pyspark import SQLContext\n",
    "\n",
    "\n",
    "# !показать, что будет, если не сделать set+memory!\n",
    "conf = SparkConf().setAppName(\"best_one\").setMaster(\"spark://spark-master:7077\").set(\"spark.executor.memory\", \"512m\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "# spark = SparkSession.\\\n",
    "#         builder.\\\n",
    "#         appName(\"best_one\").\\\n",
    "#         master(\"spark://spark-master:7077\").\\\n",
    "#         config(\"spark.executor.memory\", \"512m\").\\\n",
    "#         getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dressed-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-redhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File(\"/data/shakespeare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "meaning-eclipse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from functools import reduce\n",
    "from operator import add\n",
    "from collections import Counter\n",
    "\n",
    "# что внутри reduceByKey\n",
    "from collections import OrderedDict\n",
    "def reduce_by_key(ls):\n",
    "    d = OrderedDict()\n",
    "    for key, sublist in ls:\n",
    "        d.setdefault(key, []).extend(sublist)\n",
    "    return list(d.items())\n",
    "\n",
    "\n",
    "def agg_list(lst):\n",
    "    from collections import defaultdict\n",
    "    agg = defaultdict(lambda : 0)\n",
    "    for k, v in lst:\n",
    "        agg[k] += v\n",
    "    return list(agg.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "charming-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('',\n",
       "  [('asyoulikeit', 2),\n",
       "   ('midsummersnightsdream', 2),\n",
       "   ('muchadoaboutnothing', 2),\n",
       "   ('comedyoferrors', 2),\n",
       "   ('merrywivesofwindsor', 2),\n",
       "   ('twelfthnight', 2),\n",
       "   ('tamingoftheshrew', 2),\n",
       "   ('loveslabourslost', 2)]),\n",
       " ('a',\n",
       "  [('twelfthnight', 416),\n",
       "   ('tamingoftheshrew', 445),\n",
       "   ('loveslabourslost', 507),\n",
       "   ('asyoulikeit', 461),\n",
       "   ('midsummersnightsdream', 281),\n",
       "   ('muchadoaboutnothing', 492),\n",
       "   ('comedyoferrors', 254),\n",
       "   ('merrywivesofwindsor', 494)]),\n",
       " ('abandon',\n",
       "  [('twelfthnight', 1), ('tamingoftheshrew', 1), ('asyoulikeit', 4)]),\n",
       " ('abate',\n",
       "  [('midsummersnightsdream', 1),\n",
       "   ('tamingoftheshrew', 1),\n",
       "   ('loveslabourslost', 1)]),\n",
       " ('abatement', [('twelfthnight', 1)]),\n",
       " ('abbess', [('comedyoferrors', 8)]),\n",
       " ('abbey', [('comedyoferrors', 9)]),\n",
       " ('abbominable', [('loveslabourslost', 1)]),\n",
       " ('abbreviated', [('loveslabourslost', 1)]),\n",
       " ('abed', [('asyoulikeit', 1), ('twelfthnight', 1)])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverted Index\n",
    "sc.wholeTextFiles(\"data_shakespeare\")\\\n",
    ".map(lambda x: (x[0].split(\"/\")[-1], re.split('\\W+', x[1])))\\\n",
    ".flatMap(lambda x: [(w.lower(),(x[0], 1)) for w in x[1]])\\\n",
    ".map(lambda x: (x[0], [x[1]]))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".groupByKey()\\\n",
    ".map(lambda x : (x[0], agg_list(list(x[1])[0])))\\\n",
    ".sortByKey()\\\n",
    ".take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial-rhythm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a',\n",
       "  [('asyoulikeit', 461),\n",
       "   ('midsummersnightsdream', 281),\n",
       "   ('muchadoaboutnothing', 492),\n",
       "   ('comedyoferrors', 254),\n",
       "   ('merrywivesofwindsor', 494),\n",
       "   ('twelfthnight', 416),\n",
       "   ('tamingoftheshrew', 445),\n",
       "   ('loveslabourslost', 507)]),\n",
       " ('abandon',\n",
       "  [('asyoulikeit', 4), ('twelfthnight', 1), ('tamingoftheshrew', 1)]),\n",
       " ('abate',\n",
       "  [('tamingoftheshrew', 1),\n",
       "   ('loveslabourslost', 1),\n",
       "   ('midsummersnightsdream', 1)]),\n",
       " ('abatement', [('twelfthnight', 1)]),\n",
       " ('abbess', [('comedyoferrors', 8)]),\n",
       " ('abbey', [('comedyoferrors', 9)]),\n",
       " ('abbominable', [('loveslabourslost', 1)]),\n",
       " ('abbreviated', [('loveslabourslost', 1)]),\n",
       " ('abed', [('twelfthnight', 1), ('asyoulikeit', 1)]),\n",
       " ('abetting', [('comedyoferrors', 1)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inverted Index\n",
    "sc.wholeTextFiles(\"data_shakespeare\")\\\n",
    ".map(lambda x: (x[0].split(\"/\")[-1], re.split('\\W+', x[1])))\\\n",
    ".flatMap(lambda x: [(w.lower(),(x[0], 1)) for w in x[1] if len(w.lower()) >= 1])\\\n",
    ".map(lambda x: (x[0], [x[1]]))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".groupByKey()\\\n",
    ".map(lambda x : (x[0], agg_list(list(x[1])[0])))\\\n",
    ".sortByKey()\\\n",
    ".take(10)\n",
    "\n",
    "# можно сделать элемент 2 строкой?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rational-addiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "todf = sc.wholeTextFiles(\"data_shakespeare\")\\\n",
    ".map(lambda x: (x[0].split(\"/\")[-1], re.split('\\W+', x[1])))\\\n",
    ".flatMap(lambda x: [(w.lower(),(x[0], 1)) for w in x[1] if len(w.lower()) >= 1])\\\n",
    ".map(lambda x: (x[0], [x[1]]))\\\n",
    ".reduceByKey(lambda x,y: x + y)\\\n",
    ".groupByKey()\\\n",
    ".map(lambda x : (x[0], agg_list(list(x[1])[0])))\\\n",
    ".sortByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "accepted-renaissance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hispanic-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "several-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sqlContext.createDataFrame(todf).toDF(\"word\", \"locations_counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incorporate-darkness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|word     |locations_counts                                                                                                                                                                                        |\n",
      "+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|a        |[[asyoulikeit, 461], [midsummersnightsdream, 281], [muchadoaboutnothing, 492], [comedyoferrors, 254], [merrywivesofwindsor, 494], [twelfthnight, 416], [tamingoftheshrew, 445], [loveslabourslost, 507]]|\n",
      "|abandon  |[[asyoulikeit, 4], [twelfthnight, 1], [tamingoftheshrew, 1]]                                                                                                                                            |\n",
      "|abate    |[[tamingoftheshrew, 1], [loveslabourslost, 1], [midsummersnightsdream, 1]]                                                                                                                              |\n",
      "|abatement|[[twelfthnight, 1]]                                                                                                                                                                                     |\n",
      "|abbess   |[[comedyoferrors, 8]]                                                                                                                                                                                   |\n",
      "+---------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "intermediate-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------+\n",
      "|word|locations_counts            |\n",
      "+----+----------------------------+\n",
      "|a   |[asyoulikeit, 461]          |\n",
      "|a   |[midsummersnightsdream, 281]|\n",
      "|a   |[muchadoaboutnothing, 492]  |\n",
      "|a   |[comedyoferrors, 254]       |\n",
      "|a   |[merrywivesofwindsor, 494]  |\n",
      "+----+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# explode\n",
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "df.select(\"word\", explode(col(\"locations_counts\")).alias(\"locations_counts\")).show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "expensive-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = true)\n",
      " |-- locations_counts: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- _1: string (nullable = true)\n",
      " |    |    |-- _2: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 1\n",
    "# сделайте из этой таблцы: таблицу - \"word\", \"total_count\", \"locations\", \"counts\"\n",
    "# \"total_count\" - это общее число элемента в документе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "automated-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 2\n",
    "# повторите скрипт, используя MAGIC_COMMANG / методы DataFrame:\n",
    "# SELECT word, total_count, locations[0] AS top_location, counts[0] AS top_count \n",
    "# FROM inverted_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 3\n",
    "# Найдите слова `glove`, `gloves`, `whate` и `whatever` и найдите документ, где они чаще всего встречаются и кол-во упоминаний\n",
    "# Ваш запрос должен возвращать колонки word, total_count, top_location,\ttop_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание 4\n",
    "# 1. Используйте список стоп слов и создайте новый DataFrame, без стоп слов\n",
    "# 2. Выберите Топ-5 слов \n",
    "# 3. Сделайте новый DataFrame, имена колонок - слова из Топ-5 и total_count, а значением будет количество их встречаемости\n",
    "\n",
    "# Финальный DF\n",
    "# total_count | a | b\n",
    "# ------------|---|--\n",
    "#    1000     | 50| 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "falling-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# список стоп слов\n",
    "stp = \"\"\"\n",
    "a\n",
    "about\n",
    "above\n",
    "after\n",
    "again\n",
    "against\n",
    "all\n",
    "am\n",
    "an\n",
    "and\n",
    "any\n",
    "are\n",
    "aren't\n",
    "as\n",
    "at\n",
    "be\n",
    "because\n",
    "been\n",
    "before\n",
    "being\n",
    "below\n",
    "between\n",
    "both\n",
    "but\n",
    "by\n",
    "can't\n",
    "cannot\n",
    "could\n",
    "couldn't\n",
    "did\n",
    "didn't\n",
    "do\n",
    "does\n",
    "doesn't\n",
    "doing\n",
    "don't\n",
    "down\n",
    "during\n",
    "each\n",
    "few\n",
    "for\n",
    "from\n",
    "further\n",
    "had\n",
    "hadn't\n",
    "has\n",
    "hasn't\n",
    "have\n",
    "haven't\n",
    "having\n",
    "he\n",
    "he'd\n",
    "he'll\n",
    "he's\n",
    "her\n",
    "here\n",
    "here's\n",
    "hers\n",
    "herself\n",
    "him\n",
    "himself\n",
    "his\n",
    "how\n",
    "how's\n",
    "i\n",
    "i'd\n",
    "i'll\n",
    "i'm\n",
    "i've\n",
    "if\n",
    "in\n",
    "into\n",
    "is\n",
    "isn't\n",
    "it\n",
    "it's\n",
    "its\n",
    "itself\n",
    "let's\n",
    "me\n",
    "more\n",
    "most\n",
    "mustn't\n",
    "my\n",
    "myself\n",
    "no\n",
    "nor\n",
    "not\n",
    "of\n",
    "off\n",
    "on\n",
    "once\n",
    "only\n",
    "or\n",
    "other\n",
    "ought\n",
    "our\n",
    "ours\tourselves\n",
    "out\n",
    "over\n",
    "own\n",
    "same\n",
    "shan't\n",
    "she\n",
    "she'd\n",
    "she'll\n",
    "she's\n",
    "should\n",
    "shouldn't\n",
    "so\n",
    "some\n",
    "such\n",
    "than\n",
    "that\n",
    "that's\n",
    "the\n",
    "their\n",
    "theirs\n",
    "them\n",
    "themselves\n",
    "then\n",
    "there\n",
    "there's\n",
    "these\n",
    "they\n",
    "they'd\n",
    "they'll\n",
    "they're\n",
    "they've\n",
    "this\n",
    "those\n",
    "through\n",
    "to\n",
    "too\n",
    "under\n",
    "until\n",
    "up\n",
    "very\n",
    "was\n",
    "wasn't\n",
    "we\n",
    "we'd\n",
    "we'll\n",
    "we're\n",
    "we've\n",
    "were\n",
    "weren't\n",
    "what\n",
    "what's\n",
    "when\n",
    "when's\n",
    "where\n",
    "where's\n",
    "which\n",
    "while\n",
    "who\n",
    "who's\n",
    "whom\n",
    "why\n",
    "why's\n",
    "with\n",
    "won't\n",
    "would\n",
    "wouldn't\n",
    "you\n",
    "you'd\n",
    "you'll\n",
    "you're\n",
    "you've\n",
    "your\n",
    "yours\n",
    "yourself\n",
    "yourselves\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('') \\\n",
    "    .pivot('') \\\n",
    "    .max('') \\\n",
    "    .fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-respect",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
