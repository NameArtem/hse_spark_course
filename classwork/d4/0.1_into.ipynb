{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import CountVectorizer, CountVectorizerModel\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"spark-ml-kmeans\").getOrCreate()\n",
    "\n",
    "sparkContext = spark.sparkContext\n",
    "sqlContext = SQLContext(sparkContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# чтобы все spark работали одинаково (версии 2 и 3)\n",
    "spark.sql(\"set spark.sql.legacy.timeParserPolicy=LEGACY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создадим DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.1_into.ipynb\t\t\t        Advertising.csv\n",
      " 0_workshop_nba.ipynb\t\t       'Online Retail.csv'\n",
      " 1_rfm-empty.ipynb\t\t        SMSSpamCollection\n",
      " 1_rfm.ipynb\t\t\t        add_1_pandas_udf.ipynb\n",
      " 1_simple_binar_model.ipynb\t       'add_2_pandas_udf .ipynb'\n",
      " 2_all_data_manipulation_in_one.ipynb   banks.csv\n",
      " 3_Regression.ipynb\t\t        mails\n",
      " 4_Classification.ipynb\t\t        nbagames_short.json\n",
      " 4_Classification_empty.ipynb\t        pc.png\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - читаем файл из файла (регуляркой)\n",
    "# 2 - извлекаем первые 5 строк\n",
    "# 3 - делаем DF с разделителем # \n",
    "# 4 - сохраняем в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sed -i -e 's/\\r//g' mails/* | head -q -n 5 mails/* | paste - - - - - -d \"#\"> output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ 5 самых активных пользователей за неделю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+--------------------+---------------+----+\n",
      "|           messageid|               date|               from_|                 to_|        subject|week|\n",
      "+--------------------+-------------------+--------------------+--------------------+---------------+----+\n",
      "|Message-ID: <1705...| Mon, 6 Mar 2000 06|mike.carson@enron...|tara.sweitzer@enr...|  ENRON On_Line|  10|\n",
      "|Message-ID: <1858...|Tue, 28 Mar 2000 02|mike.carson@enron...|   m_besch@yahoo.com|     Re: Moving|  13|\n",
      "|Message-ID: <4934...| Fri, 1 Dec 2000 04|james.derrick@enr...|nbrazzil@mail.law...|Re: san antonio|  48|\n",
      "+--------------------+-------------------+--------------------+--------------------+---------------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# неделя корректно извлечена\n",
    "df1 = df.withColumn(\"week\", F.weekofyear(F.unix_timestamp(df.date, \"EEE, dd MMM yyyy HH\").cast(\"timestamp\")))\n",
    "df1.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(max(week)=48)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# максимальное значение по неделе\n",
    "maxweek = df1.agg(F.max(df1.week)).first()[0]\n",
    "print(maxweek)\n",
    "df1.agg(F.max(df1.week)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|               from_|count|\n",
      "+--------------------+-----+\n",
      "|james.derrick@enr...|    9|\n",
      "|mike.carson@enron...|    9|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"from_\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------+\n",
      "|               from_|count|avgcount|\n",
      "+--------------------+-----+--------+\n",
      "|mike.carson@enron...|    9|  0.1875|\n",
      "|james.derrick@enr...|    9|  0.1875|\n",
      "+--------------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.groupBy(\"from_\").count().withColumn(\"avgcount\", F.col(\"count\") / maxweek).sort(F.col(\"avgcount\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ ключевых слов в темах письма\n",
    "\n",
    "• для топ 5 самых активных пользователей\n",
    "\n",
    "• для малоактивных пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем токены из предложений\n",
    "tokenizer = Tokenizer().setInputCol(\"subject\").setOutputCol(\"words\")\n",
    "# трансформируем DF\n",
    "transformed = tokenizer.transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(from_='james.derrick@enron.com', count=9),\n",
       " Row(from_='mike.carson@enron.com', count=9)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# группируем, считаем количество, сортируем по убыванию\n",
    "top  = df1.groupby(\"from_\").count().sort(F.col(\"count\").desc()).take(10)\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from_': 'james.derrick@enron.com', 'count': 9}\n"
     ]
    }
   ],
   "source": [
    "# convert Row(key1=val1, key2 = val2) to Dictionary form {key1:val1, key2:val2}\n",
    "print(top[0].asDict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['james.derrick@enron.com', 'mike.carson@enron.com']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_users = [v.asDict()[\"from_\"] for v in top]\n",
    "top_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# сделаем фильтр, где будут только топовые пользователей \n",
    "topuserdata = transformed.filter(transformed.subject != \"\").filter(transformed.from_.isin(top_users))\n",
    "print(topuserdata.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+--------------------+---------------+----+-------------------+\n",
      "|           messageid|               date|               from_|                 to_|        subject|week|              words|\n",
      "+--------------------+-------------------+--------------------+--------------------+---------------+----+-------------------+\n",
      "|Message-ID: <1705...| Mon, 6 Mar 2000 06|mike.carson@enron...|tara.sweitzer@enr...|  ENRON On_Line|  10|   [enron, on_line]|\n",
      "|Message-ID: <1858...|Tue, 28 Mar 2000 02|mike.carson@enron...|   m_besch@yahoo.com|     Re: Moving|  13|      [re:, moving]|\n",
      "|Message-ID: <4934...| Fri, 1 Dec 2000 04|james.derrick@enr...|nbrazzil@mail.law...|Re: san antonio|  48|[re:, san, antonio]|\n",
      "+--------------------+-------------------+--------------------+--------------------+---------------+----+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topuserdata.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|     keyword|count|\n",
      "+------------+-----+\n",
      "|         re:|   13|\n",
      "|          st|    3|\n",
      "|           -|    3|\n",
      "|    patricks|    3|\n",
      "|    projects|    2|\n",
      "|     counsel|    2|\n",
      "|         and|    2|\n",
      "|        eecc|    2|\n",
      "|         i'm|    2|\n",
      "|      oregon|    2|\n",
      "|       lunch|    2|\n",
      "|         san|    2|\n",
      "|     outside|    2|\n",
      "|construction|    2|\n",
      "|       back!|    2|\n",
      "|     antonio|    2|\n",
      "|         bio|    1|\n",
      "|    personal|    1|\n",
      "|     on_line|    1|\n",
      "|          me|    1|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# созадим DF из топовых слов\n",
    "# колонки: слово / количество \n",
    "topuserdata.withColumn(\"keyword\", F.explode(\"words\")).groupBy(\"keyword\").count().sort(F.col(\"count\").desc()).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|keyword|count|\n",
      "+-------+-----+\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# а что ещё осталось?\n",
    "otheruserdata = transformed.filter(transformed.subject != \"\").filter(transformed.from_.isin(top_users) == False)\n",
    "otheruserdata.withColumn(\"keyword\",F.explode(\"words\")).groupBy(\"keyword\").count().sort(F.col(\"count\").desc()).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Топ 10 слов без стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|     keyword|count|\n",
      "+------------+-----+\n",
      "|         re:|   13|\n",
      "|           -|    3|\n",
      "|          st|    3|\n",
      "|    patricks|    3|\n",
      "|    projects|    2|\n",
      "|         i'm|    2|\n",
      "|     outside|    2|\n",
      "|        eecc|    2|\n",
      "|     antonio|    2|\n",
      "|       back!|    2|\n",
      "|      oregon|    2|\n",
      "|       lunch|    2|\n",
      "|         san|    2|\n",
      "|construction|    2|\n",
      "|         and|    2|\n",
      "|     counsel|    2|\n",
      "|     on_line|    1|\n",
      "|    personal|    1|\n",
      "|          30|    1|\n",
      "|     morning|    1|\n",
      "+------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "remover = StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)\n",
    "cleaned.filter(cleaned.subject != \"\").withColumn(\"keyword\",F.explode(cleaned.words)).groupBy(\"keyword\").count().sort(F.col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделаем расширенный набор стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            filtered|count|\n",
      "+--------------------+-----+\n",
      "|[outside, counsel...|   18|\n",
      "|      [st, patricks]|    8|\n",
      "| [fax, november, 30]|    7|\n",
      "|      [san, antonio]|    6|\n",
      "|             [back!]|    6|\n",
      "|[sfa, updating, p...|    6|\n",
      "|             [lunch]|    4|\n",
      "|[good, morning, ???]|    4|\n",
      "|    [enron, on_line]|    2|\n",
      "|            [moving]|    2|\n",
      "|               [bio]|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stopWords = StopWordsRemover().getStopWords() + [\"-\", \"re:\", \"fw:\"]\n",
    "remover = StopWordsRemover().setStopWords(stopWords).setInputCol(\"words\").setOutputCol(\"filtered\")\n",
    "cleaned = remover.transform(transformed)\n",
    "\n",
    "cleaned.filter(cleaned.subject != \"\").withColumn(\"keyword\",F.explode(cleaned.words)).groupBy(\"filtered\").count().sort(F.col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Определим ответные сообщения (RE:) и пересылаемые (Fw:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(msgtype=0),\n",
       " Row(msgtype=1),\n",
       " Row(msgtype=1),\n",
       " Row(msgtype=1),\n",
       " Row(msgtype=1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = cleaned.withColumn(\"msgtype\", \n",
    "                         F.when(cleaned.subject.startswith(\"Re:\"),1). \\\n",
    "                         otherwise(F.when(cleaned.subject.startswith(\"Fw:\"),2). \\\n",
    "                         otherwise(0)))\n",
    "\n",
    "df2.select(\"msgtype\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделаем Pivot по index = неделя, колонка = тип сообщения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+\n",
      "|week|   0|   1|\n",
      "+----+----+----+\n",
      "|  12|   1|   1|\n",
      "|  47|null|   1|\n",
      "|  13|null|   1|\n",
      "|  48|   1|   4|\n",
      "|  23|   1|null|\n",
      "|  10|   1|null|\n",
      "|  24|null|   2|\n",
      "|  11|   2|   3|\n",
      "+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy(\"week\").pivot(\"msgtype\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means кластеризация для извлечения слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(messageid='Message-ID: <17050056.1075858194622.JavaMail.evans@thyme>', date='Mon, 6 Mar 2000 06', from_='mike.carson@enron.com', to_='tara.sweitzer@enron.com', subject='ENRON On_Line', week=10, words=['enron', 'on_line'], filtered=['enron', 'on_line'], msgtype=0, features=SparseVector(26, {15: 1.0, 23: 1.0}))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# слова в вектор\n",
    "df4 = df2.filter(df2.subject != \"\")\n",
    "cvmodel =CountVectorizer().setInputCol(\"filtered\").setOutputCol(\"features\").fit(df4)\n",
    "featured = cvmodel.transform(df4)\n",
    "featured.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans \n",
    "kmeans = KMeans().setK(4).setSeed(28)\n",
    "model = kmeans.fit(featured)\n",
    "predictions = model.transform(featured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA для разделения слов на 4 топика (группы)\n",
    "\n",
    "[Что такое LDA](https://towardsdatascience.com/latent-dirichlet-allocation-lda-9d1cd064ffa2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+--------------------+\n",
      "|topic|    termIndices|         termWeights|\n",
      "+-----+---------------+--------------------+\n",
      "|    0| [3, 13, 22, 9]|[0.07443348665158...|\n",
      "|    1| [0, 1, 21, 20]|[0.07605311403745...|\n",
      "|    2|[17, 23, 0, 20]|[0.04347601255132...|\n",
      "|    3|  [11, 5, 6, 4]|[0.08665307397939...|\n",
      "+-----+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda = LDA().setK(4).setMaxIter(10)\n",
    "model = lda.fit(featured)\n",
    "topics = model.describeTopics(4)\n",
    "topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lunch', 'patricks', 'personal', 'oregon']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_indices = topics.select(\"termIndices\").rdd.map(lambda x:x[0][0]).collect()\n",
    "[cvmodel.vocabulary[v] for v in topic_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание:\n",
    "### Изучите файл `1_simple_binar_model.ipynb` и сделайте\n",
    "- 6 топиков для Спам\n",
    "- 6 топиков для Не Спам сообщений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
