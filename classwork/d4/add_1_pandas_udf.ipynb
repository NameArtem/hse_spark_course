{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, count, rand, collect_list, explode, struct, count, lit\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import pyarrow as pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.\\\n",
    "        builder.\\\n",
    "        appName(\"best_one\").\\\n",
    "        master(\"spark://spark-master:7077\").\\\n",
    "        config(\"spark.executor.memory\", \"512m\").\\\n",
    "        config(\"spark.sql.execution.arrow.enabled\", \"true\").\\\n",
    "        getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сделаем свободный DF для примера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|                   v|\n",
      "+---+--------------------+\n",
      "|  0| 0.49840163843008656|\n",
      "|  0|   0.069767152987945|\n",
      "|  0|  0.7190715962156708|\n",
      "|  0| 0.25640487040576976|\n",
      "|  0|  0.6416189629727991|\n",
      "|  0|  0.8528413886856091|\n",
      "|  0|  0.6129146060898196|\n",
      "|  0|  0.6164571002939396|\n",
      "|  0|  0.6396182646364857|\n",
      "|  0|  0.5752525667561637|\n",
      "|  0|  0.8052223979650148|\n",
      "|  0|  0.0405975490205146|\n",
      "|  0|0.028272580413083004|\n",
      "|  0|   0.594569306086507|\n",
      "|  0|  0.9881616666059028|\n",
      "|  0|  0.9770040363019834|\n",
      "|  0|  0.9076460273114173|\n",
      "|  0|  0.7452265863240174|\n",
      "|  0| 0.12209934414804924|\n",
      "|  0|  0.5801865543903545|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.range(0, 10 * 1000).withColumn('id', (col('id') / 10000).cast('integer')).withColumn('v', rand())\n",
    "df.cache()\n",
    "df.count()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PANDAS UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from Python worker in the executor. The below is the Python worker stacktrace.\nTraceback (most recent call last):\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 589, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 447, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 269, in read_single_udf\n    return arg_offsets, wrap_scalar_pandas_udf(func, return_type)\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 94, in wrap_scalar_pandas_udf\n    arrow_return_type = to_arrow_type(return_type)\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/pandas/types.py\", line 29, in to_arrow_type\n    import pyarrow as pa\nModuleNotFoundError: No module named 'pyarrow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c6f5c4bc9383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplus_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from Python worker in the executor. The below is the Python worker stacktrace.\nTraceback (most recent call last):\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 589, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 447, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 269, in read_single_udf\n    return arg_offsets, wrap_scalar_pandas_udf(func, return_type)\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 94, in wrap_scalar_pandas_udf\n    arrow_return_type = to_arrow_type(return_type)\n  File \"/usr/bin/spark-3.0.0-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/sql/pandas/types.py\", line 29, in to_arrow_type\n    import pyarrow as pa\nModuleNotFoundError: No module named 'pyarrow'\n"
     ]
    }
   ],
   "source": [
    "# создадим первую функцию\n",
    "\n",
    "    \n",
    "@pandas_udf('double')    # декоратор\n",
    "def plus_one(v):\n",
    "    # базовая функция на python \n",
    "    return v + 1\n",
    "\n",
    "df.withColumn('v', plus_one(df.v)).agg(count(col('v'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "1 loops, best of 3: 1.07 s per loop\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pandas_udf(\"double\", PandasUDFType.SCALAR)  # декоратор + тип данных\n",
    "def pandas_plus_one(v):\n",
    "    return v + 1\n",
    "\n",
    "%timeit df.withColumn('v', pandas_plus_one(df.v)).agg(count(col('v'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "1 loops, best of 3: 4min 13s per loop\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# итеграция других библиотек (scipy)\n",
    "\n",
    "@udf('double')\n",
    "def cdf(v):\n",
    "    return float(stats.norm.cdf(v))\n",
    "\n",
    "%timeit df.withColumn('cumulative_probability', cdf(df.v)).agg(count(col('cumulative_probability'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "+-----------------------------+\n",
       "count(cumulative_probability)|\n",
       "+-----------------------------+\n",
       "                     10000000|\n",
       "+-----------------------------+\n",
       "\n",
       "1 loops, best of 3: 1.24 s per loop\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@pandas_udf('double', PandasUDFType.SCALAR)\n",
    "def pandas_cdf(v):\n",
    "    return pd.Series(stats.norm.cdf(v))\n",
    "\n",
    "%timeit df.withColumn('cumulative_probability', pandas_cdf(df.v)).agg(count(col('cumulative_probability'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "1 loops, best of 3: 2min 4s per loop\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# передача более сложных объектов и возврат нового объекта\n",
    "@udf(ArrayType(df.schema))\n",
    "def substract_mean(rows):\n",
    "    vs = pd.Series([r.v for r in rows])\n",
    "    vs = vs - vs.mean()\n",
    "    return [Row(id=rows[i]['id'], v=float(vs[i])) for i in range(len(rows))]\n",
    "  \n",
    "%timeit df.groupby('id').agg(collect_list(struct(df['id'], df['v'])).alias('rows')).withColumn('new_rows', substract_mean(col('rows'))).withColumn('new_row', explode(col('new_rows'))).withColumn('id', col('new_row.id')).withColumn('v', col('new_row.v')).agg(count(col('v'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "+--------+\n",
       "count(v)|\n",
       "+--------+\n",
       "10000000|\n",
       "+--------+\n",
       "\n",
       "1 loops, best of 3: 4.65 s per loop\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# передача более сложных объектов и возврат нового DF (+ новая колонка)\n",
    "\n",
    "@pandas_udf(df.schema, PandasUDFType.GROUPED_MAP)\n",
    "# Input/output == pandas.DataFrame\n",
    "def pandas_subtract_mean(pdf):\n",
    "\treturn pdf.assign(v=pdf.v - pdf.v.mean())\n",
    "\n",
    "%timeit df.groupby('id').apply(pandas_subtract_mean).agg(count(col('v'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+-------------------+--------------------+-------------------+\n",
       " id|                  y|                  x1|                 x2|\n",
       "+---+-------------------+--------------------+-------------------+\n",
       "  0|  0.681296060112836|  0.1288311079969241| 0.8181088445104816|\n",
       "  0| 0.8888773955549102| 0.25520608131769806| 0.8371196660049978|\n",
       "  0|0.12865336389189674| 0.05949353129319879|0.31240880781369607|\n",
       "  0|0.33102706063173315|  0.3184970944017924| 0.9934788617057889|\n",
       "  0|0.08530551734633984|   0.849098348411309|0.25958206625946156|\n",
       "  0| 0.1142436882234027| 0.09221618780441287|0.06660852847156451|\n",
       "  0| 0.3734801477601759| 0.16175735111155454|0.23741551784520665|\n",
       "  0| 0.4626832884602221|  0.4090520759820342|0.21143786407406573|\n",
       "  0| 0.3089074870133427|  0.7875508394004922|0.20291186344825263|\n",
       "  0| 0.6963359144225203| 0.24446551311290765|0.09530396721263867|\n",
       "  0|0.18601574521309183| 0.18283878773443607| 0.9049305072841698|\n",
       "  0| 0.9986921036424282|  0.5744991393169917| 0.4377204256577574|\n",
       "  0|0.47413548244645665|  0.8647990390377169| 0.6145253333423468|\n",
       "  0| 0.8678090740409161|  0.9349286905893688|  0.897022900084491|\n",
       "  0| 0.6752577347437083| 0.20625908730646103|0.10315736062362346|\n",
       "  0|0.22669523505013633|  0.6099324032866738| 0.8357508819755833|\n",
       "  0| 0.6880907870618188|  0.8392228400945341| 0.7226505258273653|\n",
       "  0|0.30101130104653884|  0.9651274666079585| 0.5422836657606281|\n",
       "  0| 0.7195503022011948|  0.9288544640693567|0.03643847265357025|\n",
       "  0|0.27410622722360234|0.051428600469085706| 0.7646588630569261|\n",
       "+---+-------------------+--------------------+-------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df.withColumn('y', rand()).withColumn('x1', rand()).withColumn('x2', rand()).select('id', 'y', 'x1', 'x2')\n",
    "df2.show()                                                               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDF и агрегация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+---+--------------------+--------------------+\n",
       " id|                  x1|                  x2|\n",
       "+---+--------------------+--------------------+\n",
       "148|-0.00917654654646...|-0.01005665429668...|\n",
       "463|-0.01500674870033...|0.016025010035176222|\n",
       "471|-0.00832321162854...|-0.00404915919899...|\n",
       "496|-0.01122055554723648|-0.00280962655140...|\n",
       "833|-0.01629553352114...|0.002779410391406...|\n",
       "243|0.005259499685366535|0.011281848381048665|\n",
       "392|0.005589240115972826|-0.00950385069041...|\n",
       "540|5.918574070326934...|0.012159354453070217|\n",
       "623|0.020442434869455878|0.004083702101312427|\n",
       "737|0.006226657113389954|0.003961770851249408|\n",
       "858|0.001940560121997...|0.006720865070135...|\n",
       "897|-0.00142535705654...|0.004045227546180374|\n",
       " 31|0.005465606169062085|0.008832031597331093|\n",
       "516|-0.00531332000715...|0.001981946321763...|\n",
       " 85|0.012725673978444558|-0.02828045053679735|\n",
       "137|-0.00131062800808...|-5.30640018178707...|\n",
       "251|0.006229489454833485|0.002962616001996...|\n",
       "451|0.003804104279762211|-0.00447206880074...|\n",
       "580|0.026962287867315624|3.293459638984281E-4|\n",
       "808|-0.01025147566168...|0.004950671582079154|\n",
       "+---+--------------------+--------------------+\n",
       "only showing top 20 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_column = 'id'\n",
    "y_column = 'y'\n",
    "x_columns = ['x1', 'x2']\n",
    "# записываем отдельно схему колонок\n",
    "schema = df2.select(group_column, *x_columns).schema\n",
    "\n",
    "#передаем схему и тип объекта, который будет приходить на вход\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "# Input/output == pandas.DataFrame\n",
    "def ols(pdf):\n",
    "    group_key = pdf[group_column].iloc[0]\n",
    "    y = pdf[y_column]\n",
    "    X = pdf[x_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # применяем метод из библиотеки\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    # создаем новый DF\n",
    "    return pd.DataFrame([[group_key] + [model.params[i] for i in   x_columns]], columns=[group_column] + x_columns)\n",
    "\n",
    "beta = df2.groupby(group_column).apply(ols)\n",
    "beta.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "Pandas UDFs Benchmark",
  "notebookId": 3337770855798075
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
