{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "flexible-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark Logistic\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "typical-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# базовые функции\n",
    "def get_dummy(df,categoricalCols,continuousCols,labelCol):\n",
    "    from pyspark.ml import Pipeline\n",
    "    from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "    from pyspark.sql.functions import col\n",
    "    indexers = [ StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c))\n",
    "                 for c in categoricalCols ]\n",
    "\n",
    "    # декодирование фич\n",
    "    encoders = [ OneHotEncoder(inputCol=indexer.getOutputCol(),\n",
    "                 outputCol=\"{0}_encoded\".format(indexer.getOutputCol()))\n",
    "                 for indexer in indexers ]\n",
    "    \n",
    "    # сборка в колонку\n",
    "    assembler = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders]\n",
    "                                + continuousCols, outputCol=\"features\")\n",
    "\n",
    "    pipeline = Pipeline(stages=indexers + encoders + [assembler])\n",
    "\n",
    "    model=pipeline.fit(df)\n",
    "    data = model.transform(df)\n",
    "    data = data.withColumn('label',col(labelCol))\n",
    "\n",
    "    return data.select('features','label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "three-plate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------+---------+-------+-------+-------+----+-------+--------+--------+-----+--------+-------+\n",
      "|age|       job|marital|education|default|balance|housing|loan|contact|duration|campaign|pdays|previous|deposit|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+--------+--------+-----+--------+-------+\n",
      "| 59|    admin.|married|secondary|     no|   2343|    yes|  no|unknown|    1042|       1|   -1|       0|    yes|\n",
      "| 56|    admin.|married|secondary|     no|     45|     no|  no|unknown|    1467|       1|   -1|       0|    yes|\n",
      "| 41|technician|married|secondary|     no|   1270|    yes|  no|unknown|    1389|       1|   -1|       0|    yes|\n",
      "| 55|  services|married|secondary|     no|   2476|    yes|  no|unknown|     579|       1|   -1|       0|    yes|\n",
      "| 54|    admin.|married| tertiary|     no|    184|     no|  no|unknown|     673|       2|   -1|       0|    yes|\n",
      "+---+----------+-------+---------+-------+-------+-------+----+-------+--------+--------+-----+--------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv') \\\n",
    "            .options(header='true', inferschema='true') \\\n",
    "            .load(\"data/banks.csv\",header=True);\n",
    "df.drop('day','month','poutcome').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "lesbian-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deposit -> y (как переименовать?)\n",
    "\n",
    "df = # ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "noble-louisville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(29,[3,11,13,16,1...|  yes|\n",
      "|(29,[3,11,13,16,1...|  yes|\n",
      "|(29,[2,11,13,16,1...|  yes|\n",
      "|(29,[4,11,13,16,1...|  yes|\n",
      "|(29,[3,11,14,16,1...|  yes|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "catcols = ['job','marital','education','default',\n",
    "           'housing','loan','contact','poutcome']\n",
    "\n",
    "num_cols = ['balance', 'duration','campaign','pdays','previous',]\n",
    "labelCol = 'y'\n",
    "\n",
    "data = get_dummy(df,catcols,num_cols,labelCol)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "devoted-address",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------+\n",
      "|            features|label|indexedLabel|\n",
      "+--------------------+-----+------------+\n",
      "|(29,[3,11,13,16,1...|  yes|         1.0|\n",
      "|(29,[3,11,13,16,1...|  yes|         1.0|\n",
      "|(29,[2,11,13,16,1...|  yes|         1.0|\n",
      "|(29,[4,11,13,16,1...|  yes|         1.0|\n",
      "|(29,[3,11,14,16,1...|  yes|         1.0|\n",
      "+--------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# примените класс, который сделает трансформацию фичей\n",
    "# каждую переменную из указанной колонки превратит в числовое значение (в атрибут для ML)\n",
    "labelIndexer = # ваш код здесь\n",
    "labelIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dedicated-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+\n",
      "|            features|label|     indexedFeatures|\n",
      "+--------------------+-----+--------------------+\n",
      "|(29,[3,11,13,16,1...|  yes|(29,[3,11,13,16,1...|\n",
      "|(29,[3,11,13,16,1...|  yes|(29,[3,11,13,16,1...|\n",
      "|(29,[2,11,13,16,1...|  yes|(29,[2,11,13,16,1...|\n",
      "|(29,[4,11,13,16,1...|  yes|(29,[4,11,13,16,1...|\n",
      "|(29,[3,11,14,16,1...|  yes|(29,[3,11,14,16,1...|\n",
      "+--------------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# примените класс, который сделает трансформацию \n",
    "# добавит indexedLabel к features и укажет для алгоритма, что это целевое значение\n",
    "featureIndexer = # ваш код здесь\n",
    "featureIndexer.transform(data).show(5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "included-chicago",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                       |label|\n",
      "+-----------------------------------------------------------------------------------------------+-----+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,37.0,84.0,11.0,-1.0])|no   |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,80.0,155.0,3.0,-1.0])|no   |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,99.0,15.0,5.0,-1.0]) |no   |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,189.0,90.0,2.0,-1.0])|no   |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,333.0,80.0,6.0,-1.0])|no   |\n",
      "+-----------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------------------------------------------------------------------------------------+-----+\n",
      "|features                                                                                          |label|\n",
      "+--------------------------------------------------------------------------------------------------+-----+\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,-382.0,644.0,12.0,-1.0])|yes  |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,123.0,154.0,2.0,-1.0])  |no   |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,149.0,1222.0,2.0,-1.0]) |yes  |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,215.0,1141.0,4.0,-1.0]) |yes  |\n",
      "|(29,[0,11,13,16,17,18,19,21,24,25,26,27],[1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,355.0,314.0,3.0,-1.0])  |no   |\n",
      "+--------------------------------------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train / test split\n",
    "(trainingData, testData) = # сделайте разбивку на train (70%) / test (30%) \n",
    "\n",
    "trainingData.show(5,False)\n",
    "testData.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "intense-accent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Классификаторы\n",
    "# Сделайте выбор классификатора\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "increasing-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = #\n",
    "dTree = #\n",
    "nb = #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "caroline-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !\n",
    "# Нет XGBoost в Spark\n",
    "# надо использовать (http://docs.h2o.ai/sparkling-water/2.1/latest-stable/doc/pysparkling.html)\n",
    "# или https://xgboost.readthedocs.io/en/latest/jvm/xgboost4j_spark_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "secondary-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# оформите архитектуру pipeline\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", \n",
    "                               outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "pipeline = Pipeline(stages=[labelIndexer, \n",
    "                            featureIndexer, \n",
    "                            # алгоритм,\n",
    "                            labelConverter])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "appointed-watts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------+\n",
      "|            features|label|predictedLabel|\n",
      "+--------------------+-----+--------------+\n",
      "|(29,[0,11,13,16,1...|  yes|           yes|\n",
      "|(29,[0,11,13,16,1...|   no|            no|\n",
      "|(29,[0,11,13,16,1...|  yes|           yes|\n",
      "|(29,[0,11,13,16,1...|  yes|           yes|\n",
      "|(29,[0,11,13,16,1...|   no|           yes|\n",
      "+--------------------+-----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "predictions = model.transform(testData)\n",
    "predictions.select(\"features\",\"label\",\"predictedLabel\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "different-contrast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.209125\n"
     ]
    }
   ],
   "source": [
    "# оцените качество\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator() # укажите нужные параметры в скобках\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "medical-enhancement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                 FPR|                TPR|\n",
      "+--------------------+-------------------+\n",
      "|                 0.0|                0.0|\n",
      "|0.001418439716312...|0.01926721415034744|\n",
      "|0.003404255319148936|0.03790271636133923|\n",
      "|0.004539007092198...| 0.0574857864813645|\n",
      "|0.005673758865248227|0.07706885660138976|\n",
      "+--------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "areaUnderROC: 0.8875113685747952\n"
     ]
    }
   ],
   "source": [
    "lrModel = model.stages[2]\n",
    "trainingSummary = lrModel.summary\n",
    "\n",
    "# ROC_AUC\n",
    "trainingSummary.roc.show(5)\n",
    "print(\"areaUnderROC: \" + str(trainingSummary.areaUnderROC))\n",
    "\n",
    "# F-mesuare\n",
    "# а какая метрика была бы полезна ещё? Почему?\n",
    "fMeasure = trainingSummary.fMeasureByThreshold\n",
    "maxFMeasure = fMeasure.groupBy().max('F-Measure').select('max(F-Measure)').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "proud-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# исследуйте локально \n",
    "# %pyspark\n",
    "# https://github.com/jupyter-incubator/sparkmagic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
